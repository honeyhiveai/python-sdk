# Development Best Practices - HoneyHive Python SDK

## Development Environment Setup

### Mandatory Code Quality Process

**‚ö†Ô∏è CRITICAL: Install Pre-commit Hooks**
```bash
# One-time setup (required for all developers)
./scripts/setup-dev.sh
```

**Automatic Quality Enforcement** (only runs when relevant files change):
- **Black formatting**: 88-character lines, applied when Python files change
- **Import sorting**: isort with black profile, applied when Python files change
- **Static analysis**: pylint + mypy type checking when Python files change
- **YAML validation**: yamllint with 120-character lines when YAML files change
- **Documentation checks**: Only when docs/Agent OS files change
- **Tox verification**: Scoped to relevant file types for efficiency

**Before Every Commit**:
1. Pre-commit hooks run automatically (DO NOT bypass)
2. Manual verification: `tox -e format && tox -e lint`
3. **MANDATORY**: All tests must pass - `tox -e unit && tox -e integration`
4. **MANDATORY for AI Assistants**: Update documentation before committing
5. **MANDATORY for AI Assistants**: Use correct dates - `date +"%Y-%m-%d"` command
6. Emergency bypass only: `git commit --no-verify` (document why and fix immediately)

**Documentation Update Requirements**:
- **Code changes**: CHANGELOG.md must be updated
- **New features**: CHANGELOG.md + docs/reference/index.rst + .agent-os/product/features.md
- **Workflow changes**: Update docs/development/testing/ and .agent-os/standards/
- **Large changesets (>3 files)**: Comprehensive documentation review required
- **AI Assistant commits**: Automatic documentation compliance checking

### Required Tools
```bash
# Core development tools
pip install yamllint>=1.37.0  # YAML validation for workflows
brew install gh               # GitHub CLI for workflow investigation

# Verify installation
yamllint --version
gh --version
```

### Tool Usage Patterns
- **yamllint**: Validate GitHub Actions YAML syntax before commits
- **GitHub CLI**: Investigate workflow failures, view run logs, manage releases
- **Docker**: Required for Lambda testing and container validation

## Git Branching Strategy

### Branch Model
**HoneyHive Python SDK follows a simplified branching model:**

- **`main`**: The only protected branch containing production-ready code
- **All other branches**: Temporary working feature branches (deleted after merge)

### Branch Types
```bash
# Feature branches (temporary)
feature/add-anthropic-support
feature/improve-error-handling
bugfix/fix-span-serialization
docs/update-api-reference
refactor/modernize-architecture

# Current working branches (temporary)
complete-refactor    # Major architecture changes
develop             # Legacy branch (will be removed)
```

### Workflow Rules

**‚úÖ DO:**
- Create feature branches from `main`
- Use descriptive branch names: `feature/`, `bugfix/`, `docs/`, `refactor/`
- Open PRs targeting `main` when ready for review
- Delete feature branches after successful merge
- Rebase feature branches to keep history clean

**‚ùå DON'T:**
- Consider any branch other than `main` as permanent
- Create long-lived development branches
- Merge directly to `main` without PR review
- Push directly to `main` (use PRs for all changes)

### CI/CD Trigger Strategy

**GitHub Actions Workflows:**
```yaml
push:
  branches: [main]  # Only run on pushes to the protected main branch
pull_request:
  # Run on ALL PRs - immediate feedback on feature branch work
```

**Rationale:**
- **No duplicates**: Feature branch pushes only trigger via PR workflows
- **Immediate feedback**: All PRs get tested regardless of target branch
- **Gate keeping**: Direct pushes to `main` get validated (though should be rare)
- **Resource efficient**: Single workflow run per feature branch change

### Branch Lifecycle
1. **Create**: `git checkout -b feature/my-feature main`
2. **Develop**: Regular commits with quality checks on every push
3. **Integrate**: Open PR to `main` when ready
4. **Review**: Automated + manual review process
5. **Merge**: Squash merge to `main` with clean commit message
6. **Cleanup**: Delete feature branch immediately after merge

## Architecture Principles

### Multi-Instance Support
- Each tracer instance is independent
- No global singleton pattern
- Thread-safe initialization
- Support for multiple concurrent tracers
- Clear instance lifecycle management

### Separation of Concerns
```python
# Clear layer separation
src/honeyhive/
‚îú‚îÄ‚îÄ api/           # API client layer
‚îú‚îÄ‚îÄ tracer/        # OpenTelemetry integration
‚îú‚îÄ‚îÄ evaluation/    # Evaluation framework
‚îú‚îÄ‚îÄ models/        # Data models
‚îî‚îÄ‚îÄ utils/         # Shared utilities
```

### Dependency Injection
```python
# Pass dependencies explicitly
tracer = HoneyHiveTracer(
    api_key="key",
    project="project",
    instrumentors=[OpenAIInstrumentor()]  # Inject instrumentors
)

# Use factory methods for complex initialization
tracer = HoneyHiveTracer.init(
    api_key="key",
    server_url="https://custom.honeyhive.ai"
)
```

## SDK Design Patterns

### Graceful Degradation
```python
def create_session(self) -> Optional[str]:
    """Create session with graceful failure."""
    try:
        response = self.api.create_session()
        return response.session_id
    except Exception as e:
        if not self.test_mode:
            logger.warning(f"Session creation failed: {e}")
        # Continue without session - don't crash host app
        return None
```

### Decorator Pattern
```python
# Unified decorator for sync/async
@trace(event_type=EventType.model)
def sync_function():
    pass

@trace(event_type=EventType.model)
async def async_function():
    pass

# Class-level decoration
@trace_class
class MyService:
    def method(self):
        pass  # Automatically traced
```

### Context Management
```python
# Use context managers for resource management
with tracer.start_span("operation") as span:
    # Span automatically closed on exit
    result = perform_operation()
    span.set_attribute("result", result)

# Enrich span context manager
with enrich_span(event_type=EventType.tool):
    # Enrichment applied to current span
    process_data()
```

## Error Handling Strategy

### Exception Hierarchy
```python
class HoneyHiveError(Exception):
    """Base exception for all HoneyHive errors."""

class ConfigurationError(HoneyHiveError):
    """Configuration-related errors."""

class APIError(HoneyHiveError):
    """API communication errors."""
    
class RateLimitError(APIError):
    """Rate limit exceeded."""
    
class AuthenticationError(APIError):
    """Authentication failed."""
```

### Retry Logic
```python
@retry(
    max_attempts=3,
    backoff_factor=2.0,
    exceptions=(httpx.TimeoutException, httpx.NetworkError)
)
async def make_api_call():
    """API call with exponential backoff retry."""
    return await client.post(url, json=data)
```

### Error Logging
```python
# Log at appropriate levels
logger.debug("Detailed trace information")
logger.info("Normal operation status")
logger.warning("Recoverable issues")
logger.error("Errors that need attention")
logger.critical("System failures")

# Include context in error messages
logger.error(
    "API call failed",
    extra={
        "url": url,
        "status_code": response.status_code,
        "project": self.project,
        "trace_id": span.get_span_context().trace_id
    }
)
```

## Performance Optimization

### Connection Pooling
```python
# Reuse HTTP connections
connection_pool = ConnectionPool(
    max_connections=config.max_connections,
    max_keepalive_connections=config.max_keepalive_connections,
    keepalive_expiry=config.keepalive_expiry
)

# Share client across requests
self._client = httpx.AsyncClient(
    limits=httpx.Limits(
        max_connections=100,
        max_keepalive_connections=20
    )
)
```

### Batching Operations
```python
# Batch span exports
class BatchSpanProcessor:
    def __init__(self, max_batch_size=512, schedule_delay_millis=5000):
        self.batch = []
        self.max_batch_size = max_batch_size
        
    def on_end(self, span):
        self.batch.append(span)
        if len(self.batch) >= self.max_batch_size:
            self._export_batch()
```

### Async Best Practices
```python
# Use async for I/O operations
async def fetch_data(urls: List[str]):
    """Fetch data concurrently."""
    async with httpx.AsyncClient() as client:
        tasks = [client.get(url) for url in urls]
        responses = await asyncio.gather(*tasks)
    return responses

# Don't block the event loop
# Bad: time.sleep(1)
# Good: await asyncio.sleep(1)
```

## Testing Strategy

### Test Organization
```
tests/
‚îú‚îÄ‚îÄ unit/              # Fast, isolated tests
‚îÇ   ‚îú‚îÄ‚îÄ test_api_client.py
‚îÇ   ‚îú‚îÄ‚îÄ test_tracer_decorators.py
‚îÇ   ‚îî‚îÄ‚îÄ test_utils_config.py
‚îú‚îÄ‚îÄ integration/       # API integration tests
‚îÇ   ‚îú‚îÄ‚îÄ test_openai_integration.py
‚îÇ   ‚îî‚îÄ‚îÄ test_langchain_integration.py
‚îî‚îÄ‚îÄ fixtures/         # Shared test fixtures
```

### Testing Best Practices
```python
# Always use tox for testing
# tox -e unit       # Unit tests
# tox -e integration # Integration tests
# tox -e py311     # Python 3.11 tests

# Mock external dependencies
@patch('honeyhive.api.client.httpx.AsyncClient')
def test_api_call(mock_client):
    """Test API call with mocked client."""
    mock_client.post.return_value = Mock(json={"success": True})

# Use fixtures for common setup
@pytest.fixture
def configured_tracer():
    """Provide configured tracer for tests."""
    return HoneyHiveTracer(
        api_key="test-key",
        test_mode=True
    )
```

## Testing Standards - MANDATORY FOR ALL COMMITS

**üö® CRITICAL RULE: Zero Failing Tests Policy**

**ALL commits with new features, bug fixes, or code changes MUST have 100% passing tests.**

### Pre-Commit Testing Requirements

**MANDATORY Test Execution**:
```bash
# Required before ANY commit
tox -e unit           # Must pass 100%
tox -e integration    # Must pass 100%
tox -e lint          # Must pass 100%
tox -e format        # Must pass 100%

# For Python version compatibility
tox -e py311 -e py312 -e py313  # All must pass
```

**‚ùå NEVER COMMIT if any tests fail**
**‚ùå NEVER SKIP TESTS** - AI assistants must fix failing tests, never skip them
**‚ùå NEVER use `git commit --no-verify` without immediate follow-up fix**
**‚ùå NEVER push failing tests to any branch (including development branches)**

### ‚ùå PROHIBITED: Test Skipping

**AI assistants are STRICTLY FORBIDDEN from skipping failing tests.**

#### Forbidden Patterns
```python
# ‚ùå FORBIDDEN - Never skip tests
@pytest.mark.skip(reason="Temporarily skipped - will fix later")
def test_broken_feature():
    pass

# ‚ùå FORBIDDEN - Never comment out failing tests  
# def test_that_fails():
#     assert broken_function() == expected

# ‚ùå FORBIDDEN - Never disable in tox.ini
# Removing failing test environments from tox.ini
```

#### Required Approach
```python
# ‚úÖ REQUIRED - Fix the underlying issue
def test_that_works():
    # Proper setup and mocking
    with patch("module.dependency") as mock_dep:
        mock_dep.return_value = expected_response
        result = function_under_test()
        assert result == expected_result
```

#### When Tests Fail: Mandatory Steps
1. **Investigate**: Understand the root cause
2. **Debug**: Use print statements, debugger, or logging
3. **Fix**: Address the underlying issue (code or mock setup)
4. **Validate**: Ensure the fix works and doesn't break other tests
5. **Never Skip**: Skipping creates technical debt and hides problems

### New Feature Requirements

**For ANY new feature or functionality:**

1. **Feature Implementation**: Write the feature code
2. **Test Implementation**: Write comprehensive tests that cover:
   - Happy path scenarios
   - Error conditions
   - Edge cases
   - Backward compatibility (if applicable)
3. **Test Verification**: All tests must pass locally
4. **Integration Check**: Feature must not break existing functionality
5. **Documentation**: Update relevant docs and examples

### Test Coverage Requirements
- **New code**: Minimum 80% coverage required
- **Modified code**: Cannot decrease existing coverage
- **Critical paths**: 100% coverage required (API clients, decorators, core functionality)
- **Overall project**: Minimum 70% coverage maintained

### Development Branch Testing Policy

**Even on development branches:**
- **No exceptions**: All tests must pass before pushing
- **Work-in-progress**: Use local commits, squash before pushing
- **Feature branches**: Must have passing tests for each logical commit
- **Draft PRs**: Can have failing tests, but must be fixed before review

### CI/CD Integration

**Automated enforcement:**
- GitHub Actions will block merges if tests fail
- Pre-commit hooks prevent local commits with obvious issues
- Tox environments ensure consistent testing across all environments
- Coverage reports must meet minimum thresholds

**Failure Response Protocol:**
1. **Immediate action**: Stop all work on new features
2. **Fix tests**: Address failing tests as highest priority
3. **Root cause analysis**: Understand why tests failed
4. **Prevention**: Update practices to prevent similar failures

### Testing Requirements by Change Type

**Bug Fixes:**
- Must include test that reproduces the bug
- Test must fail before fix, pass after fix
- Regression test must be added to prevent reoccurrence

**New Features:**
- Comprehensive test suite covering all functionality
- Integration tests showing feature works with existing code
- Performance tests if feature affects performance
- Documentation examples must be tested

**Refactoring:**
- All existing tests must continue to pass
- No decrease in test coverage
- May require updating test implementation (not removing tests)

**Documentation Changes:**
- All code examples in docs must be tested
- Examples must use current API patterns
- Integration with existing documentation must be verified

### Emergency Procedures

**If tests fail after commit:**
1. **Immediate revert**: Revert the failing commit
2. **Fix locally**: Address the test failures
3. **Re-commit**: Only after all tests pass
4. **Post-mortem**: Document what went wrong and how to prevent it

**For critical hotfixes:**
- All testing requirements still apply
- No exceptions for "urgent" fixes

### Instrumentor Integration Requirements - MANDATORY

**üö® ALL NEW INSTRUMENTOR INTEGRATIONS MUST INCLUDE**:

**1. Compatibility Matrix Test**: `tests/compatibility_matrix/test_[provider]_[instrumentor].py`
- Complete integration test with actual provider API calls
- Error handling validation (auth errors, rate limits, network failures)
- Performance benchmarking (latency, throughput metrics)
- Multi-configuration testing (different models, parameters)
- State management verification (for agent-based instrumentors)
- Real API credential testing (with proper environment variable setup)

**2. Integration Documentation**: `docs/how-to/integrations/[provider]-[instrumentor].rst`
- Quick start guide with installation instructions
- Basic usage examples with working code
- Advanced configuration patterns
- Error handling and reliability patterns
- Performance monitoring and optimization
- Environment configuration for dev/staging/production
- Best practices and common pitfalls
- Comparison with similar providers/instrumentors

**3. Example Implementation**: `examples/simple_[provider]_[instrumentor]_integration.py`
- Complete working example demonstrating integration
- Proper error handling and graceful degradation
- Environment variable configuration with clear setup instructions
- Type hints and comprehensive docstrings
- Real-world usage patterns (basic usage, advanced features, multi-step workflows)
- Executable standalone script with proper main() function
- Clear success/failure exit codes and user feedback
- Examples of tracing enrichment and custom span attributes

**4. Multi-Provider Documentation Update**: `docs/how-to/integrations/multi-provider.rst`
- Add new instrumentor to provider comparison table
- Include in multi-provider example code
- Update capability matrix with instrumentor features
- Add to provider selection guidance

**5. Integration Index Update**: `docs/how-to/integrations/index.rst`
- Add to provider list with clear description
- Include in integration overview section
- Update provider comparison table
- Add to recommended provider combinations

**6. Feature Catalog Update**: `.agent-os/product/features.md`
- Add instrumentor to compatibility matrix
- Update provider support table
- Document new capabilities enabled
- Add to roadmap if applicable

**7. Compatibility Matrix Environment Documentation**: `tests/compatibility_matrix/README.md`
- Add all required environment variables for the new instrumentor
- Include provider-specific API key requirements
- Document authentication setup steps
- Update the "Complete Environment Setup" section
- Add troubleshooting guidance for provider-specific issues
- Include provider in the supported providers table with status

**8. Examples Directory Documentation**: `examples/README.md`
- Add new example to the appropriate provider integration section
- Include clear description of what the example demonstrates
- Link to the example file with proper formatting
- Update provider integration examples list
- Ensure example follows the documented patterns and conventions

**üîç Pre-Commit Validation Checklist**:
- [ ] Compatibility test passes with real API credentials
- [ ] Documentation builds without Sphinx warnings
- [ ] All code examples are executable and tested
- [ ] Integration guide follows Divio documentation standards
- [ ] Multi-provider docs include new instrumentor
- [ ] CHANGELOG.md updated with new integration details
- [ ] Feature catalog reflects new capabilities
- [ ] Example code includes proper error handling
- [ ] Performance benchmarks are reasonable (if applicable)
- [ ] Type hints are complete and accurate
- [ ] Compatibility matrix README updated with environment variables
- [ ] Supported providers table includes new instrumentor
- [ ] Environment setup section covers new provider requirements
- [ ] Troubleshooting section addresses provider-specific issues
- [ ] Examples directory README updated with new example
- [ ] Example file is executable and demonstrates key features
- [ ] Example includes proper error handling and environment setup
- [ ] Documentation navigation validation passes locally
- [ ] All new documentation files included in appropriate toctree
- [ ] Cross-references between documentation sections work correctly
- [ ] Integration with main navigation structure verified

**üìã Quality Gates**:
- **Documentation Quality**: Must pass `tox -e docs` with `-W` flag (warnings as errors)
- **Navigation Validation**: Must pass `python docs/utils/validate_navigation.py --local`
- **Code Quality**: Must pass `tox -e lint` (pylint ‚â•8.0/10.0, mypy clean)
- **Test Coverage**: Compatibility test must achieve ‚â•80% code coverage
- **Example Validation**: All examples must be executable via `python examples/[file].py`
- **Integration Testing**: Must pass in CI/CD environment with mock/test credentials
- **Post-Deployment Validation**: Navigation validation must pass against live site

**‚ùå PROHIBITED**:
- Instrumentor integrations without complete documentation
- Tests that require manual credential setup without environment fallbacks
- Documentation that references non-existent features
- Examples that use hardcoded credentials or non-generic configurations
- Compatibility tests that skip functionality due to "complexity"
- Adding new instrumentors without updating compatibility matrix environment documentation
- Missing environment variable documentation for new provider integrations
- Incomplete provider setup instructions in compatibility matrix README

### ‚ùå PROHIBITED: Invalid Tracer Decorator Patterns - MANDATORY

**üö® CRITICAL**: The `@tracer.trace(...)` decorator pattern is NOT supported in HoneyHive SDK**:

**Invalid Patterns (DO NOT USE)**:
```python
# ‚ùå NEVER USE - This pattern does not exist in HoneyHive SDK
@tracer.trace(event_type=EventType.chain, event_name="agent_benchmark")
def my_function():
    pass

# ‚ùå NEVER USE - HoneyHiveTracer has no trace method for decorators
@my_tracer.trace(event_type=EventType.tool)
def process_data():
    pass
```

**Correct Patterns (USE THESE)**:
```python
# ‚úÖ CORRECT: Standalone trace decorator with explicit tracer
from honeyhive import trace, EventType

@trace(tracer=tracer, event_type=EventType.chain, event_name="agent_benchmark")
def my_function():
    pass

# ‚úÖ CORRECT: Standalone trace decorator with automatic discovery
@trace(event_type=EventType.chain, event_name="agent_benchmark")
def my_function():
    pass

# ‚úÖ CORRECT: Context manager for manual span control
with tracer.start_span("operation_name") as span:
    # Manual span management
    pass
```

**Why This Matters**:
- **API Consistency**: HoneyHiveTracer class has no `trace()` method that returns a decorator
- **Documentation Accuracy**: Prevents confusion and incorrect examples
- **Code Quality**: Ensures all tracing code uses supported patterns
- **Backward Compatibility**: Maintains consistency with both main and complete-refactor branches

**üîç Common Sources of Confusion**:
- **Other SDKs**: Some observability SDKs do provide `@tracer.trace()` patterns
- **OpenTelemetry**: Raw OpenTelemetry has different patterns than HoneyHive
- **Intuitive Assumption**: It seems logical that `@tracer.trace()` would exist alongside `tracer.start_span()`

**üìã Validation Checklist**:
- [ ] All examples use `@trace(tracer=tracer, ...)` or `@trace(...)`
- [ ] No instances of `@tracer.trace(...)` or `@*.trace(...)` in documentation
- [ ] Context manager usage correctly uses `tracer.start_span()` or `tracer.trace()` (context manager form)
- [ ] All trace decorators import from `honeyhive` module: `from honeyhive import trace`
- [ ] Run validation: `grep -r "@.*\.trace(" docs/` should return no results
- [ ] All code examples include proper import statements

### Integration Documentation Navigation - MANDATORY

**üö® ALL INTEGRATION PAGES MUST INCLUDE CONSISTENT "SEE ALSO" NAVIGATION**:

**Required "See Also" Section Template**:
```rst
See Also
--------

- :doc:`multi-provider` - Use [Current Provider] with other providers
- :doc:`../troubleshooting` - Common integration issues  
- :doc:`../../tutorials/03-llm-integration` - LLM integration tutorial
```

**Navigation Principles**:
- **Keep it minimal**: Only 3-4 essential links that users actually need
- **Focus on value**: Multi-provider setup, troubleshooting, and learning path
- **Avoid link spam**: Don't list every other integration (users can find those via index)
- **Be consistent**: Same structure and essential links across all integration pages

**‚ùå PROHIBITED Navigation Patterns**:
- Exhaustive lists of all other integrations (creates maintenance burden)
- Links to niche advanced topics (better discovered organically)  
- Complex automation systems that require maintenance scripts
- Dead or outdated cross-references

**‚úÖ REQUIRED Navigation Links**:
1. **Multi-provider**: Always relevant for users wanting to combine providers
2. **Troubleshooting**: Practical when integration issues arise
3. **Tutorial**: Clear learning path for new users

**üìã Integration Page Validation**:
- [ ] Page has "See Also" section with exactly 3 essential links
- [ ] Multi-provider link uses current provider name in description
- [ ] All links are verified working during docs build
- [ ] Navigation follows consistent rst formatting

### Tutorial Integration Coverage - MANDATORY

**üö® ALL NEW LLM INSTRUMENTORS MUST BE ADDED TO TUTORIAL**:

**Required Tutorial Integration**: `docs/tutorials/03-llm-integration.rst`

**Mandatory Tutorial Section Template**:
```rst
[Provider Name] Integration
---------------------------

[Brief description of provider and use cases]

**Step 1: Install [Provider] Instrumentor**

.. code-block:: bash

   pip install openinference-instrumentation-[provider]

**Step 2: Set Up [Provider] Tracing**

.. code-block:: python

   from honeyhive import HoneyHiveTracer
   from openinference.instrumentation.[provider] import [Provider]Instrumentor
   import [provider-package]
   
   # Initialize with [Provider] instrumentor
   tracer = HoneyHiveTracer.init(
       api_key="your-honeyhive-api-key",
       project="[provider]-tutorial",
       instrumentors=[[Provider]Instrumentor()]
   )
   
   # Configure [Provider]
   [provider-specific-setup]
   
   def example_function(prompt: str) -> str:
       """Example function showing [Provider] usage."""
       
       # Working example with actual provider API
       [provider-api-call]
       
       return result

**Step 3: Test Your Integration**

.. code-block:: python

   # Example call that demonstrates tracing
   result = example_function("Example prompt")
   print(f"Result: {result}")
```

**Tutorial Integration Requirements**:

1. **Placement**: Add section between existing providers and "Advanced: Custom Instrumentor"
2. **Working Example**: Include complete, executable code example
3. **Real API Usage**: Demonstrate actual provider API calls, not pseudocode
4. **Environment Setup**: Show how to configure provider credentials
5. **Clear Naming**: Use `[provider]-tutorial` project naming convention
6. **Practical Use Case**: Choose example that showcases provider's strengths

**üìã Tutorial Validation Checklist**:
- [ ] New provider section added to `docs/tutorials/03-llm-integration.rst`
- [ ] Section follows the standard template structure  
- [ ] Code example is complete and executable
- [ ] Proper imports for both HoneyHive and provider
- [ ] Environment variable setup documented
- [ ] Example demonstrates actual provider API usage
- [ ] Tutorial maintains logical flow between providers
- [ ] Prerequisites updated if new provider has unique requirements

**‚ùå PROHIBITED Tutorial Patterns**:
- Adding instrumentor without tutorial coverage
- Pseudocode examples that aren't executable
- Missing import statements in code examples
- Generic examples that don't showcase provider capabilities
- Incomplete setup instructions for provider credentials

**üìö Documentation Standards**:
- All instrumentor docs must follow the Divio Documentation System (Tutorials, How-to, Reference, Explanation)
- Code examples must use `EventType` enums, never string literals
- All examples must include proper `from honeyhive.models import EventType` imports
- Error handling patterns must be consistent across all instrumentor documentation
- Performance considerations must be documented for resource-intensive instrumentors

### Documentation Navigation Validation - MANDATORY

**üö® ALL NEW DOCUMENTATION MUST PASS NAVIGATION VALIDATION**:

**Automatic Validation Requirements**:
- All new `.rst` files are automatically discovered and validated
- Navigation validation runs on every documentation deployment
- Broken links, missing pages, and navigation errors block deployment
- Cross-references between documentation sections must be valid

**Pre-Commit Documentation Validation**:
```bash
# Local validation before committing
python docs/utils/validate_navigation.py --local

# Validate against production after deployment
python docs/utils/validate_navigation.py --base-url https://honeyhiveai.github.io/python-sdk/
```

**Mandatory Navigation Requirements**:
1. **Toctree Inclusion**: All new documentation files must be included in appropriate toctree
2. **Cross-Reference Validation**: Internal links must resolve correctly
3. **Navigation Structure**: New sections must integrate with existing navigation
4. **Search Integration**: New content must be searchable via Sphinx search
5. **Mobile Compatibility**: Navigation must work on mobile devices

**üîÑ Self-Updating Validation**:
- Documentation validation automatically discovers new files
- No manual updates to validation lists required
- New instrumentor documentation is automatically included
- Navigation validation adapts as documentation grows

**‚ö†Ô∏è Common Navigation Issues to Prevent**:
- New `.rst` files not added to any toctree
- Broken cross-references after restructuring
- Missing index pages for new sections
- Orphaned documentation files
- Invalid internal link targets
- Missing or broken integration with main navigation

**üîç Validation Scope**:
- **All Documentation Pages**: Every `.rst` file that becomes an `.html` page
- **Navigation Links**: All internal navigation and toctree links
- **Cross-References**: Links between different documentation sections
- **Search Functionality**: Sphinx search index and search page
- **Structural Integrity**: Main navigation, breadcrumbs, and section organization

**üìã Automatic Quality Gates**:
- **Post-Deployment Validation**: MANDATORY validation after every documentation deployment
- **GitHub Actions**: Runs automatically on `workflow_run` completion and `push` to main
- **Pre-commit Hooks**: Local validation prevents broken navigation commits
- **Deployment Blocking**: Failed navigation validation = failed deployment
- **Weekly Monitoring**: Scheduled validation catches deployment drift
- **Manual Triggers**: On-demand validation for specific URL testing

**‚ùå PROHIBITED Navigation Patterns**:
- Adding new documentation without toctree inclusion
- Creating orphaned pages that can't be reached via navigation
- Broken internal links that return 404 errors
- Navigation structures that don't follow Divio documentation system
- Instrumentor documentation that isn't linked from integration index
- Cross-references that break after documentation restructuring
- Fast tracking through expedited review, not skipped testing

## Date and Timestamp Standards - MANDATORY FOR AI ASSISTANTS

**üö® CRITICAL ISSUE**: AI Assistants consistently make date errors that create confusion and misaligned documentation.

### Mandatory Date Usage Protocol

**ALWAYS use the system date command before creating dated content:**

```bash
# REQUIRED: Get current date before ANY date-related work
CURRENT_DATE=$(date +"%Y-%m-%d")
echo "Today is: $CURRENT_DATE"

# Use this variable for all date references
echo "Creating spec for date: $CURRENT_DATE"
```

### Date Format Standards

**Standard Format**: `YYYY-MM-DD` (ISO 8601)
- ‚úÖ **Correct**: `2025-09-03`
- ‚ùå **Wrong**: `2025-01-30` (when today is 2025-09-03)
- ‚ùå **Wrong**: `09/03/2025`, `Sep 3, 2025`, `3-9-2025`

### AI Assistant Date Requirements

#### For New Specifications
```bash
# 1. Get current date
CURRENT_DATE=$(date +"%Y-%m-%d")

# 2. Create directory with current date
mkdir -p ".agent-os/specs/${CURRENT_DATE}-spec-name"

# 3. Use date in file headers
echo "**Date**: $CURRENT_DATE" > spec-file.md
```

#### For File Naming
- **Directories**: `.agent-os/specs/YYYY-MM-DD-spec-name/`
- **Files**: `YYYY-MM-DD-feature-name.md`
- **Logs**: `build-YYYY-MM-DD.log`
- **Releases**: `v1.2.3-YYYY-MM-DD`

#### For Documentation Headers
```markdown
# Specification Title

**Date**: 2025-09-03
**Status**: Active
**Last Updated**: 2025-09-03
**Review Date**: 2025-10-03
```

### Common Date Errors to Prevent

#### Error Pattern 1: Using Random Past Dates
‚ùå **Wrong**:
```bash
mkdir .agent-os/specs/2025-01-30-new-spec  # Created in September!
```

‚úÖ **Correct**:
```bash
CURRENT_DATE=$(date +"%Y-%m-%d")
mkdir ".agent-os/specs/${CURRENT_DATE}-new-spec"
```

#### Error Pattern 2: Hardcoded Dates in Content
‚ùå **Wrong**:
```markdown
**Date**: 2025-01-30  <!-- Hardcoded wrong date -->
```

‚úÖ **Correct**:
```bash
CURRENT_DATE=$(date +"%Y-%m-%d")
echo "**Date**: $CURRENT_DATE" >> spec.md
```

#### Error Pattern 3: Inconsistent Date Formats
‚ùå **Wrong**:
- `January 30, 2025`
- `30-01-2025`
- `1/30/2025`

‚úÖ **Correct**:
- `2025-09-03` (always ISO 8601)

### Date Validation Checklist

**Before creating ANY dated content:**

1. **Get Current Date**: `date +"%Y-%m-%d"`
2. **Verify Output**: Confirm the date makes sense
3. **Use Variable**: Store in variable for consistency
4. **Validate Creation**: Check directory/file names match current date
5. **Review Headers**: Ensure all date headers use current date

### Directory Naming Protocol

**For new specifications:**
```bash
# Template
.agent-os/specs/YYYY-MM-DD-specification-name/

# Example (if today is 2025-09-03)
.agent-os/specs/2025-09-03-new-feature-spec/
.agent-os/specs/2025-09-03-ai-quality-framework/
.agent-os/specs/2025-09-03-testing-standards/
```

**NEVER use old or random dates in new directories!**

### Automated Date Injection

**For AI Assistants - use this template:**

```bash
#!/bin/bash
# Date-aware specification creation template

# Get current date
CURRENT_DATE=$(date +"%Y-%m-%d")
SPEC_NAME="$1"  # First argument is spec name

# Create directory
SPEC_DIR=".agent-os/specs/${CURRENT_DATE}-${SPEC_NAME}"
mkdir -p "$SPEC_DIR"

# Create README with correct date
cat > "$SPEC_DIR/README.md" << EOF
# Specification: $SPEC_NAME

**Date**: $CURRENT_DATE
**Status**: Draft
**Last Updated**: $CURRENT_DATE

## Overview
[Specification content here]
EOF

echo "Created specification: $SPEC_DIR"
echo "Date used: $CURRENT_DATE"
```

### Date Review and Maintenance

#### Weekly Reviews
- **Audit existing specs**: Check for date inconsistencies
- **Update "Last Updated"**: Refresh modified specifications
- **Archive old specs**: Move outdated specs to archive directory

#### Monthly Reviews
- **Validate date patterns**: Ensure consistency across all files
- **Update review dates**: Extend review cycles for stable specs
- **Clean up directories**: Remove any incorrectly dated directories

### Emergency Date Correction Protocol

**If wrong dates are discovered:**

1. **Stop all work**: Halt current development
2. **Identify scope**: Find all affected files/directories
3. **Create fix plan**: Plan correction strategy
4. **Execute corrections**: Rename directories, update headers
5. **Validate fixes**: Ensure all dates are now correct
6. **Document lessons**: Update this protocol if needed

### Date Quality Metrics

**Track these metrics to prevent date errors:**
- **Specification Date Accuracy**: % of specs with correct creation dates
- **Directory Naming Consistency**: % of directories following date standards
- **Header Date Validity**: % of files with accurate date headers
- **Review Date Compliance**: % of specs with up-to-date review dates

### Enforcement Mechanisms

#### Pre-commit Hooks
```bash
# Add to pre-commit validation
check_dates() {
    # Validate new spec directories use current date
    CURRENT_DATE=$(date +"%Y-%m-%d")
    
    # Check for directories created today
    NEW_DIRS=$(git diff --cached --name-only | grep "\.agent-os/specs/" | head -1)
    if [[ $NEW_DIRS == *"specs/"* ]] && [[ $NEW_DIRS != *"$CURRENT_DATE"* ]]; then
        echo "ERROR: New spec directory must use current date: $CURRENT_DATE"
        exit 1
    fi
}
```

#### CI/CD Validation
```yaml
# GitHub Actions date validation
- name: Validate Specification Dates
  run: |
    CURRENT_DATE=$(date +"%Y-%m-%d")
    # Check for any new specs with wrong dates
    NEW_SPECS=$(git diff --name-only HEAD~1 HEAD | grep "\.agent-os/specs/")
    for spec in $NEW_SPECS; do
        if [[ $spec == *"specs/"* ]] && [[ $spec != *"$CURRENT_DATE"* ]]; then
            echo "ERROR: Specification uses wrong date: $spec"
            echo "Expected date: $CURRENT_DATE"
            exit 1
        fi
    done
```

## Commit Message Standards - MANDATORY

**üö® CRITICAL ISSUE**: AI Assistants consistently make commit message formatting errors.

### Mandatory Commit Message Protocol

**ALWAYS follow Conventional Commits format:**
- **Title**: `<type>: <description>` (max 50 chars)
- **NO unnecessary quotes**: Don't wrap titles in quotes
- **Match quotes properly**: If you start a quote, close it
- **Types**: feat, fix, docs, style, refactor, perf, test, build, ci, chore

### Common Errors to Prevent

```bash
# ‚ùå WRONG - Missing closing quote
git commit -m "feat: Add feature

# ‚ùå WRONG - Unnecessary quotes
git commit -m "\"feat: Add feature\""

# ‚ùå WRONG - Too long (71 chars)
git commit -m "feat: Add comprehensive documentation quality control system validation"

# ‚úÖ CORRECT
git commit -m "feat: Add documentation quality control"
```

### Validation Requirements

**Before EVERY commit:**
1. Check title length ‚â§ 50 characters
2. Verify conventional commit format
3. Ensure proper quote matching
4. No periods at end of title

## Security Practices

### API Key Management
```python
# Never log API keys
def __init__(self, api_key: str):
    self.api_key = api_key
    logger.info("Client initialized")  # Don't log the key!

# Validate API key format
if not api_key or not api_key.startswith("hh_"):
    raise ValueError("Invalid API key format")

# Support key rotation
def rotate_api_key(self, new_key: str):
    """Update API key without restart."""
    self.api_key = new_key
    self._reinitialize_client()
```

### Data Privacy
```python
# Redact sensitive data
def redact_pii(data: Dict[str, Any]) -> Dict[str, Any]:
    """Redact PII from data."""
    sensitive_keys = ["ssn", "email", "phone", "credit_card"]
    return {
        k: "***REDACTED***" if k in sensitive_keys else v
        for k, v in data.items()
    }

# Configurable data filtering
if config.redact_inputs:
    inputs = redact_pii(inputs)
```

## Configuration Management

### Environment Variable Patterns
```python
# Support multiple prefixes for compatibility
api_key = (
    os.getenv("HH_API_KEY") or
    os.getenv("HONEYHIVE_API_KEY") or
    os.getenv("API_KEY")
)

# Configuration precedence
# 1. Constructor parameters (highest)
# 2. HH_* environment variables
# 3. Standard environment variables
# 4. Default values (lowest)
```

### Configuration Validation
```python
class Config:
    def __init__(self):
        self.api_key = self._validate_api_key()
        self.timeout = self._validate_timeout()
        
    def _validate_timeout(self) -> float:
        """Validate and parse timeout value."""
        timeout = os.getenv("HH_TIMEOUT", "30.0")
        try:
            value = float(timeout)
            if value <= 0:
                raise ValueError("Timeout must be positive")
            return value
        except (ValueError, TypeError):
            logger.warning(f"Invalid timeout: {timeout}, using default")
            return 30.0
```

## Documentation Requirements

### Code Documentation
- Every module needs a docstring
- Every public function needs a docstring
- Complex logic requires inline comments
- Include usage examples in docstrings

### User Documentation - Divio System

**üéØ Following the [Divio Documentation System](https://docs.divio.com/documentation-system/)**

The HoneyHive SDK documentation is organized into four distinct types, each serving different user needs:

#### 1. TUTORIALS (Learning-oriented)
**Purpose**: Help newcomers get started and achieve early success
**User mindset**: "I want to learn by doing"

**Structure**:
```
tutorials/
‚îú‚îÄ‚îÄ 01-quick-start.rst          # 5-minute setup
‚îú‚îÄ‚îÄ 02-basic-tracing.rst        # First traces with @trace decorator
‚îú‚îÄ‚îÄ 03-llm-integration.rst      # OpenAI/Anthropic integration
‚îú‚îÄ‚îÄ 04-evaluation-basics.rst    # First evaluation
‚îî‚îÄ‚îÄ 05-dashboard-tour.rst       # Understanding HoneyHive UI
```

**Content Requirements**:
- Step-by-step instructions
- Clear learning objectives
- Working code examples
- Expected outcomes at each step
- Maximum 15-20 minutes per tutorial
- Test with actual beginners

#### 2. HOW-TO GUIDES (Problem-oriented)
**Purpose**: Solve specific real-world problems
**User mindset**: "I want to solve this specific problem"

**Structure**:
```
how-to/
‚îú‚îÄ‚îÄ troubleshooting.rst         # Common issues and solutions
‚îú‚îÄ‚îÄ deployment/                 # Production deployment guides
‚îú‚îÄ‚îÄ integrations/              # LLM provider integrations
‚îú‚îÄ‚îÄ advanced-tracing/          # Complex tracing scenarios
‚îú‚îÄ‚îÄ evaluation/                # Evaluation workflows
‚îú‚îÄ‚îÄ testing/                   # Testing strategies
‚îî‚îÄ‚îÄ monitoring/                # Performance and error tracking
```

**Content Requirements**:
- Problem-focused titles
- Minimal background explanation
- Clear steps to solution
- Multiple approaches when applicable
- Prerequisites clearly stated
- Links to reference docs

#### 3. REFERENCE (Information-oriented)
**Purpose**: Provide comprehensive technical specifications
**User mindset**: "I need to look up exact details"

**Structure**:
```
reference/
‚îú‚îÄ‚îÄ api/                       # Complete API documentation
‚îú‚îÄ‚îÄ configuration/             # All configuration options
‚îú‚îÄ‚îÄ data-models/              # Data structure specifications
‚îú‚îÄ‚îÄ cli/                      # CLI command reference
‚îî‚îÄ‚îÄ evaluation/               # Evaluator specifications
```

**Content Requirements**:
- Complete API coverage
- Accurate parameter descriptions
- Return value specifications
- Error condition documentation
- Code examples for each function
- Cross-references between related items

#### 4. EXPLANATION (Understanding-oriented)
**Purpose**: Provide context, background, and design decisions
**User mindset**: "I want to understand how this works and why"

**Structure**:
```
explanation/
‚îú‚îÄ‚îÄ architecture/              # SDK design and architecture
‚îú‚îÄ‚îÄ concepts/                  # Core concepts and terminology
‚îú‚îÄ‚îÄ decisions/                 # Design decision rationale
‚îî‚îÄ‚îÄ comparisons/              # Comparisons with alternatives
```

**Content Requirements**:
- Conceptual explanations
- Design decision rationale
- Architecture overviews
- Historical context when relevant
- Comparison with alternatives
- Future direction insights

### Documentation Best Practices

#### Type Safety and Code Examples

**MANDATORY: Proper Type Usage in All Documentation**

All code examples in documentation MUST follow strict type safety guidelines:

```python
# ‚úÖ CORRECT: Proper enum imports and usage
from honeyhive import HoneyHiveTracer, trace, atrace
from honeyhive.models import EventType

@trace(event_type=EventType.model)  # Type-safe enum value
def llm_function():
    """Process LLM requests."""
    pass

@trace(event_type=EventType.tool)   # Individual function/utility
def utility_function():
    """Process individual data operations."""
    pass

@trace(event_type=EventType.chain)  # Multi-step workflow
def workflow_function():
    """Orchestrate multiple operations."""
    pass

# ‚ùå INCORRECT: String literals (deprecated, breaks type safety)
@trace(event_type="model")  # Never use string literals
def bad_function():
    pass
```

**EventType Semantic Guidelines**:
- **EventType.model**: LLM calls, AI model inference, generation
- **EventType.tool**: Individual functions, utilities, data processing, validation
- **EventType.chain**: Workflows, multi-step processes, business logic orchestration  
- **EventType.session**: High-level sessions, complete user interactions

**Validation Requirements**:
1. ‚úÖ **Import Validation**: Every code example includes correct imports
2. ‚úÖ **Type Checking**: All examples pass mypy validation
3. ‚úÖ **Enum Usage**: No string literals for enum values anywhere
4. ‚úÖ **Import Order**: honeyhive imports first, then models
5. ‚úÖ **Consistency**: Same patterns across tutorials, how-to, reference
6. ‚úÖ **Semantic Correctness**: EventType matches actual function purpose

**AI Assistant Requirements**:
When updating documentation, AI assistants MUST:
- Validate all imports are correct and complete
- Replace string literals with proper enum values
- Test code examples for syntax correctness
- Follow EventType semantic mapping guidelines
- Update import statements when adding enum usage
- Maintain consistency across all files

#### Documentation Error Prevention Protocol

**MANDATORY: Pre-generation validation checklist**

1. ‚úÖ **RST Structure Validation**:
   - Title underlines MUST match title length exactly
   - Blank lines MUST separate sections and headers
   - Code blocks MUST have proper indentation (3 spaces)
   - Tables MUST use consistent column formatting

2. ‚úÖ **Type Safety Enforcement**:
   - NO string literals in `event_type` parameters
   - ALL `@trace` decorators MUST use `EventType` enums
   - Complete import statements MUST be included
   - Import validation MUST pass before generation

3. ‚úÖ **Code Example Integrity**:
   - Python syntax MUST be valid (AST parseable)
   - All imports MUST resolve correctly
   - Examples MUST follow project standards
   - No orphaned code fragments allowed

4. ‚úÖ **Structural Compliance**:
   - All files MUST be included in toctrees
   - Cross-references MUST resolve correctly
   - No broken internal links allowed
   - Section hierarchy MUST be logical

**Error Prevention Tools** (See `.agent-os/specs/2025-09-03-documentation-quality-prevention/`):
- Pre-commit validation hooks
- Automated RST quality checking
- Type safety enforcement
- Code example testing
- Structural integrity verification

#### Content Creation Guidelines
```python
# Every tutorial should follow this pattern:
"""
1. Clear objective statement
2. Prerequisites list
3. Step-by-step instructions
4. Code examples with explanations
5. Expected results
6. Next steps recommendations
7. Troubleshooting section
"""

# How-to guides should be problem-focused:
"""
Title: "How to trace custom LLM providers"
Not: "Custom LLM provider documentation"

Structure:
- Problem statement
- Solution overview
- Step-by-step implementation
- Verification steps
- Common pitfalls
"""
```

#### Cross-linking Strategy
- Tutorials link to relevant how-to guides
- How-to guides reference specific API docs
- Reference docs link to conceptual explanations
- Explanations provide context for tutorials

#### Content Maintenance
```bash
# Regular content audits
docs/utils/audit-content.py      # Check for broken links
docs/utils/test-examples.py      # Verify all code examples work
docs/utils/validate-structure.py # Ensure Divio compliance
```

#### User Testing Protocol
1. **Tutorial Testing**: Test with 3+ new users monthly
2. **How-to Validation**: Verify solutions work in real scenarios
3. **Reference Accuracy**: Automated testing of API examples
4. **Explanation Clarity**: Expert review for technical accuracy

### Maintenance Documentation
- Architecture decisions (in `explanation/decisions/`)
- Design patterns used (in `explanation/architecture/`)
- Performance considerations (in `explanation/concepts/`)
- Security implications (in `how-to/deployment/`)
- Known limitations (in `reference/` sections)

## Release Process

### Version Management
```
# Semantic Versioning: MAJOR.MINOR.PATCH
0.1.0 - Initial beta release
0.1.1 - Bug fixes
0.2.0 - New features (backwards compatible)
1.0.0 - First stable release
2.0.0 - Breaking changes
```

### Release Checklist
- [ ] Update version in pyproject.toml
- [ ] Update CHANGELOG.md
- [ ] Run full test suite with tox
- [ ] Build documentation
- [ ] Create git tag
- [ ] Build and publish to PyPI
- [ ] Update GitHub release notes
- [ ] Notify users of breaking changes

### Backwards Compatibility
```python
# Deprecation warnings
def old_method(self):
    """Deprecated method."""
    warnings.warn(
        "old_method is deprecated, use new_method instead",
        DeprecationWarning,
        stacklevel=2
    )
    return self.new_method()

# Support multiple API versions
if api_version == "v1":
    return self._handle_v1_response(response)
else:
    return self._handle_v2_response(response)
```

## Development Workflow

### Code Review Process
1. Create feature branch
2. Implement changes
3. Write/update tests
4. Update documentation
5. Run tox locally
6. Create pull request
7. Address review feedback
8. Merge after approval

### Continuous Integration & CI/CD Best Practices

**Multi-Tier Testing Strategy** (see [CI/CD GitHub Actions Specification](../specs/2025-09-02-cicd-gha-best-practices/specs.md)):

- **Tier 1: Continuous Testing** - Fast feedback on every PR/push (5-10 minutes)
  - Run core tests on all Python versions (3.11, 3.12, 3.13)
  - Check code formatting with black and isort
  - Measure test coverage (minimum 70% requirement)
  - Validate YAML syntax with yamllint
  - Docker simulation testing for AWS Lambda compatibility

- **Tier 2: Daily Scheduled Testing** - Comprehensive validation (30-60 minutes)
  - Performance benchmarking with statistical significance
  - Real AWS Lambda environment testing
  - Security scans and dependency vulnerability checks
  - Build and deploy documentation
  - Performance regression detection

- **Tier 3: Release Candidate Testing** - Complete validation (45-90 minutes)
  - All tier 1 & 2 tests plus integration validation
  - Package building and distribution testing
  - Cross-platform testing (Ubuntu, Windows, macOS)
  - Quality gates for production deployment

**GitHub Actions Workflow Optimization**:

- **Smart Job Organization** - Reduce PR interface clutter through composite jobs
- **Conditional Execution** - Branch and commit message-based test triggering
- **Modern Action Versions** - Use latest stable actions (v4/v5)
- **Artifact Management** - Comprehensive test result preservation
- **Duplicate Prevention** - Optimize triggers to prevent redundant executions

### Developer Experience
- Clear error messages
- Helpful debug output
- Good IDE support
- Quick feedback loops
- Comprehensive examples
- Active community support

## Common Pitfalls to Avoid

### Anti-Patterns
- ‚ùå Global state
- ‚ùå Mutable default arguments
- ‚ùå Bare except clauses
- ‚ùå Hardcoded values
- ‚ùå Synchronous I/O in async code
- ‚ùå Memory leaks from circular references

### Best Practices
- ‚úÖ Explicit is better than implicit
- ‚úÖ Fail fast with clear errors
- ‚úÖ Log liberally but carefully
- ‚úÖ Test edge cases
- ‚úÖ Document assumptions
- ‚úÖ Keep it simple

## Performance Guidelines

### Profiling
```python
# Profile before optimizing
import cProfile
import pstats

profiler = cProfile.Profile()
profiler.enable()
# Code to profile
profiler.disable()
stats = pstats.Stats(profiler)
stats.sort_stats('cumulative')
stats.print_stats(10)
```

### Memory Management
- Use generators for large datasets
- Clear caches periodically
- Avoid circular references
- Use weak references where appropriate
- Monitor memory usage in tests

### Optimization Priorities
1. Correctness first
2. Readability second
3. Performance third
4. Measure before optimizing
5. Document optimizations

## AI Assistant Development Process Requirements

### ü§ñ Mandatory AI Assistant Validation Process

**‚ö†Ô∏è CRITICAL**: AI assistants must follow strict validation protocols to prevent codebase drift and outdated reference errors.

#### Pre-Generation Validation (MANDATORY)

Before generating ANY code that integrates with the codebase:

1. **üìã Current API Validation**:
   ```bash
   # ALWAYS check current exports first
   read_file src/honeyhive/__init__.py
   grep -r "class.*:" src/honeyhive/api/
   ```

2. **üîç Import Pattern Verification**:
   ```bash
   # Check current import patterns in examples
   grep -r "from honeyhive import" examples/
   grep -r "import honeyhive" tests/
   ```

3. **üìö Current Usage Pattern Analysis**:
   - Read at least 2-3 current example files
   - Check recent test files for current API usage
   - Verify class names and method signatures

#### Workflow/CI Generation Rules (MANDATORY)

**üö® Never generate CI/CD workflows without codebase validation**:

1. **Current API Check**: Read `__init__.py` and `__all__` exports
2. **Test Pattern Review**: Check `tests/` for current import patterns  
3. **Example Validation**: Verify against `examples/` directory
4. **Documentation Cross-Check**: Ensure consistency with current docs

#### Case Study: HoneyHiveClient Failure (2025-09-02)

**‚ùå What Happened**: AI assistant generated workflow using `HoneyHiveClient` (deprecated Aug 28) instead of `HoneyHive` (current API)

**üîç Root Cause**: Generated code from memory/assumptions instead of current codebase validation

**‚úÖ Prevention**: Mandatory pre-generation codebase validation prevents this failure mode

#### AI Assistant Commit Requirements

**All AI assistant commits MUST**:
1. **Validate current API** before generating integration code
2. **Test generated code** against current codebase
3. **Update documentation** to reflect any changes
4. **Include validation evidence** in commit messages

**Example compliant commit message**:
```
feat: add release candidate workflow

VALIDATION EVIDENCE:
- Checked src/honeyhive/__init__.py exports: HoneyHive, HoneyHiveTracer
- Verified examples/basic_usage.py import patterns
- Tested against current API surface
- All imports validated against __all__ exports
```

#### Emergency Override Process

**Only in genuine emergencies**:
1. Document why validation was skipped
2. Add TODO for immediate post-emergency validation
3. Schedule validation within 24 hours
4. Update Agent OS with lessons learned

### üîÑ Continuous Validation Requirements

**For Long-Running Development Sessions**:
- Re-validate API every 50+ file changes
- Check for deprecation warnings before major code generation
- Refresh codebase understanding if session > 2 hours
- Always validate before final commits
