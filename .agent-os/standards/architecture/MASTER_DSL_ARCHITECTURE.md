# Master DSL Architecture - Unified Documentation

**Date**: 2025-09-30  
**Purpose**: Unified architecture for the complete DSL system - from source to runtime  
**Scope**: Provider schemas â†’ Semantic conventions â†’ YAML DSL â†’ O(1) indexes â†’ Cross-language runtime

---

## ğŸ“‹ Table of Contents

1. [System Overview](#system-overview)
2. [The Complete Pipeline](#the-complete-pipeline)
3. [Phase 1: Provider Schema Extraction](#phase-1-provider-schema-extraction)
4. [Phase 2: Semantic Convention Discovery](#phase-2-semantic-convention-discovery)
5. [Phase 3: YAML DSL Configuration](#phase-3-yaml-dsl-configuration)
6. [Phase 4: Bundle Compilation](#phase-4-bundle-compilation)
7. [Phase 5: Cross-Language Runtime](#phase-5-cross-language-runtime)
8. [Tools & Utilities](#tools--utilities)
9. [Release Process](#release-process)

---

## ğŸ¯ System Overview

### **The Problem**

HoneyHive needs to:
1. Support **any instrumentor** (OpenLit, Traceloop, OpenInference) - BYOI architecture
2. Support **any provider** (OpenAI, Anthropic, etc.) - neutrality
3. Support **multiple languages** (Python, TypeScript, Go) - platform-wide
4. Handle **complex LLM responses** (tool calls, multimodal, etc.) - data fidelity
5. **Zero code changes** when providers/instrumentors update - config-driven

### **The Solution**

A **unified DSL system** that:
- Extracts provider schemas programmatically
- Discovers semantic conventions from instrumentor source
- Compiles to YAML DSL (single source of truth)
- Generates O(1) optimized bundles
- Loads in any language with no code changes

---

## ğŸ”„ The Complete Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 1: PROVIDER SCHEMA EXTRACTION                         â”‚
â”‚ (What fields exist in provider API responses?)              â”‚
â”‚                                                             â”‚
â”‚ Input:  OpenAPI specs, SDK types, API docs                 â”‚
â”‚ Tool:   Provider Schema Extraction Framework               â”‚
â”‚ Output: provider_response_schemas/{provider}/              â”‚
â”‚         â”œâ”€â”€ v{version}.json (JSON Schema)                  â”‚
â”‚         â”œâ”€â”€ examples/*.json (validated examples)           â”‚
â”‚         â””â”€â”€ CRITICAL_FINDINGS.md (DSL guidance)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 2: SEMANTIC CONVENTION DISCOVERY                      â”‚
â”‚ (What attributes do instrumentors set?)                     â”‚
â”‚                                                             â”‚
â”‚ Input:  Instrumentor GitHub repos                          â”‚
â”‚ Tool:   analyze_instrumentor_source.py                     â”‚
â”‚ Output: config/semantic_conventions/{instrumentor}/        â”‚
â”‚         â”œâ”€â”€ source_analysis.yaml (discovered attrs)        â”‚
â”‚         â””â”€â”€ {provider}.yaml.template (auto-generated)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 3: YAML DSL CONFIGURATION                             â”‚
â”‚ (How to detect, extract, and map?)                         â”‚
â”‚                                                             â”‚
â”‚ Human Curation:                                             â”‚
â”‚   1. Use provider schema to understand fields              â”‚
â”‚   2. Use semantic convention discovery for attributes      â”‚
â”‚   3. Create YAML configs:                                  â”‚
â”‚                                                             â”‚
â”‚ config/dsl/providers/{provider}/                            â”‚
â”‚ â”œâ”€â”€ structure_patterns.yaml    # Detection                 â”‚
â”‚ â”œâ”€â”€ navigation_rules.yaml      # Extraction                â”‚
â”‚ â”œâ”€â”€ transforms.yaml             # Transformations          â”‚
â”‚ â””â”€â”€ field_mappings.yaml         # HoneyHive mapping        â”‚
â”‚                                                             â”‚
â”‚ config/semantic_conventions/{instrumentor}/                 â”‚
â”‚ â””â”€â”€ {provider}.yaml             # Instrumentor mappings    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 4: BUNDLE COMPILATION                                 â”‚
â”‚ (Compile to O(1) optimized bundle)                         â”‚
â”‚                                                             â”‚
â”‚ Tool:   compile_dsl_bundle.py                              â”‚
â”‚ Output: config/dsl/compiled/dsl-bundle.json                â”‚
â”‚                                                             â”‚
â”‚ Bundle Structure:                                           â”‚
â”‚ â”œâ”€â”€ signature_index: {}      # O(1) provider detection     â”‚
â”‚ â”œâ”€â”€ extractors: {}            # O(1) extraction rules       â”‚
â”‚ â”œâ”€â”€ mappings: {}              # O(1) field mappings         â”‚
â”‚ â””â”€â”€ transforms: {}            # Transform registry          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PHASE 5: CROSS-LANGUAGE RUNTIME                             â”‚
â”‚ (Load bundle in any language, no code changes)             â”‚
â”‚                                                             â”‚
â”‚ Python:     dsl_interpreter.py + dsl-bundle.json           â”‚
â”‚ TypeScript: dsl-interpreter.ts + dsl-bundle.json           â”‚
â”‚ Go:         dsl_interpreter.go + dsl-bundle.json           â”‚
â”‚                                                             â”‚
â”‚ All use SAME bundle, SAME O(1) performance                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Phase 1: Provider Schema Extraction

### **Purpose**

Extract and validate the **actual structure** of provider API responses.

### **Why This Matters**

- Provider responses are complex (tool calls with JSON strings, multimodal, etc.)
- Need to know **what fields exist** before building DSL
- Critical findings inform DSL design (e.g., "arguments is a JSON string, not object")

### **Framework**

**Location**: `.agent-os/standards/ai-assistant/provider-schema-extraction/`

**Phases**:
0. Pre-Research Setup
1. Schema Discovery (find OpenAPI specs, SDK types)
2. Schema Extraction (download and parse)
3. Example Collection (gather real responses)
4. JSON Schema Creation (convert to JSON Schema)
5. Validation (test examples against schema)
6. Documentation (document critical findings)
7. Integration Testing (ready for DSL)

### **Output Structure**

```
provider_response_schemas/
â””â”€â”€ {provider}/                    # e.g., openai
    â”œâ”€â”€ v{version}.json            # JSON Schema (e.g., v2025-01-30.json)
    â”œâ”€â”€ examples/                  # Validated examples
    â”‚   â”œâ”€â”€ basic_chat.json
    â”‚   â”œâ”€â”€ tool_calls.json
    â”‚   â”œâ”€â”€ refusal.json
    â”‚   â”œâ”€â”€ audio_response.json
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ CHANGELOG.md               # Version history
    â”œâ”€â”€ CRITICAL_FINDINGS.md       # DSL integration guidance
    â”œâ”€â”€ SDK_SOURCES.md             # Source tracking
    â”œâ”€â”€ PROVIDER_INFO.md           # Provider metadata
    â””â”€â”€ validate_schema.py         # Validation tool
```

### **Critical Findings Example (OpenAI)**

```markdown
# From CRITICAL_FINDINGS.md

ğŸš¨ Tool Call Arguments are JSON STRINGS
- Type: `string` (JSON-serialized, NOT object)
- DSL Impact: Must preserve as JSON string, not parse

ğŸš¨ Content Can Be Null
- Null when `tool_calls` or `refusal` is primary response
- DSL Impact: Requires null-safe extraction with fallback

ğŸš¨ Arrays are Flattened in Instrumentor Spans
- Instrumentors flatten to: `gen_ai.completion.0.message.tool_calls.0.id`
- DSL Impact: Must reconstruct arrays with `reconstruct_array_from_flattened()`
```

### **How This Feeds Into DSL**

```yaml
# Provider schema tells us:
# - tool_calls is an array
# - function.arguments is a JSON string
# - Can be null

# This informs DSL navigation rules:
navigation_rules:
  traceloop_tool_calls_flattened:
    source_field: "gen_ai.completion.0.message.tool_calls"
    extraction_method: "array_reconstruction"  # â† From schema type
    preserve_json_strings: true                # â† From schema format
    json_string_fields:
      - "function.arguments"                   # â† From schema definition
```

---

## ğŸ” Phase 2: Semantic Convention Discovery

### **Purpose**

Discover **what attributes instrumentors actually set** on spans.

### **Why This Matters**

- Can't manually track every instrumentor's attributes
- Instrumentors evolve and add new attributes
- Need programmatic discovery for accuracy

### **Tool: Instrumentor Source Analyzer**

**Script**: `scripts/analyze_instrumentor_source.py`

**What it does**:
1. Clones instrumentor GitHub repos
2. Scans Python source code using AST parsing
3. Finds all `span.set_attribute()` calls
4. Identifies signature vs optional attributes
5. Generates YAML templates

**Usage**:
```bash
python scripts/analyze_instrumentor_source.py traceloop
```

**Output**:
```
config/semantic_conventions/traceloop/
â”œâ”€â”€ source_analysis.yaml       # Discovered attributes
â””â”€â”€ openai.yaml.template       # Auto-generated template
```

### **Auto-Generated Template**

```yaml
# config/semantic_conventions/traceloop/openai.yaml.template
# Auto-discovered from source analysis

version: '0.46.2'
instrumentor: traceloop
provider: openai

detection:
  # Auto-discovered signature attributes
  signature_attributes:
    - "gen_ai.system"
    - "gen_ai.request.model"
    - "gen_ai.usage.prompt_tokens"
  
  # Auto-discovered optional attributes
  optional_attributes:
    - "gen_ai.usage.completion_tokens"
    - "gen_ai.response.model"
    - "gen_ai.completion"

# Human fills in mappings below:
mappings:
  inputs: {}
  outputs: {}
  config: {}
  metadata: {}
```

### **Human Curation**

After auto-generation, humans fill in the mappings:

```yaml
# config/semantic_conventions/traceloop/openai.yaml
# Human-curated mappings

mappings:
  outputs:
    tool_calls:
      source: "gen_ai.completion.0.message.tool_calls.*"
      transform: "reconstruct_array_from_flattened"
      params:
        prefix: "gen_ai.completion.0.message.tool_calls"
        preserve_json_strings: true           # â† From provider schema!
        json_string_fields:
          - "function.arguments"              # â† From CRITICAL_FINDINGS!
```

**Key**: Provider schema informs the semantic convention mapping!

---

## ğŸ“ Phase 3: YAML DSL Configuration

### **Purpose**

Create the **single source of truth** for detection, extraction, and mapping logic.

### **Two Types of YAML Configs**

#### **Type 1: Provider DSL** (Provider-centric)

**Location**: `config/dsl/providers/{provider}/`

**Files**:

1. **structure_patterns.yaml** - How to detect provider
   ```yaml
   patterns:
     openinference_openai:
       signature_fields:
         - "llm.model_name"
         - "llm.provider"
       confidence_weight: 0.95
       instrumentor_framework: "openinference"
   ```

2. **navigation_rules.yaml** - How to extract fields
   ```yaml
   navigation_rules:
     traceloop_tool_calls_flattened:
       source_field: "gen_ai.completion.0.message.tool_calls"
       extraction_method: "array_reconstruction"
       preserve_json_strings: true
   ```

3. **transforms.yaml** - How to transform data
   ```yaml
   transforms:
     extract_tool_calls:
       function_type: "array_reconstruction"
       implementation: "reconstruct_array_from_flattened"
       parameters:
         preserve_json_strings: true
   ```

4. **field_mappings.yaml** - How to map to HoneyHive schema
   ```yaml
   outputs:
     tool_calls:
       source_rule: "traceloop_tool_calls_flattened"
       transform: "extract_tool_calls"
       required: false
   ```

#### **Type 2: Semantic Convention DSL** (Instrumentor-centric)

**Location**: `config/semantic_conventions/{instrumentor}/`

**Files**:

```yaml
# config/semantic_conventions/traceloop/openai.yaml

version: '0.46.2'
instrumentor: traceloop
provider: openai

detection:
  signature_attributes: [...]
  constraints:
    "gen_ai.system": {"equals": "openai"}

mappings:
  outputs:
    tool_calls:
      source: "gen_ai.completion.0.message.tool_calls.*"
      transform: "reconstruct_array_from_flattened"
      params:
        prefix: "gen_ai.completion.0.message.tool_calls"
        preserve_json_strings: true
```

### **How They Work Together**

The compiler **merges** both types:
1. Provider DSL defines overall structure
2. Semantic conventions add instrumentor-specific details
3. Both compile to the same unified bundle

---

## ğŸ”§ Phase 4: Bundle Compilation

### **Purpose**

Compile YAML configs into an **O(1) optimized bundle** for runtime.

### **Tool: Bundle Compiler**

**Script**: `scripts/compile_dsl_bundle.py`

**What it does**:
1. Loads all YAML configs (provider DSL + semantic conventions)
2. Merges and validates
3. Builds O(1) indexes:
   - **Signature index**: attribute set â†’ provider (O(1) detection)
   - **Extractor index**: provider:instrumentor â†’ steps (O(1) extraction)
   - **Mapping index**: provider â†’ fields (O(1) mapping)
4. Outputs optimized JSON bundle

**Usage**:
```bash
python scripts/compile_dsl_bundle.py --output config/dsl/compiled/dsl-bundle.json
```

### **Bundle Format (O(1) Optimized)**

```json
{
  "version": "4.0",
  "build_timestamp": "2025-09-30T12:00:00Z",
  
  // ========================================
  // INDEX 1: O(1) Signature Index
  // ========================================
  "signature_index": {
    // Key: sorted attribute signature
    // Value: provider match
    "gen_ai.request.model|gen_ai.system|gen_ai.usage.prompt_tokens": {
      "provider": "openai",
      "instrumentor": "traceloop",
      "confidence": 0.90
    }
  },
  
  // ========================================
  // INDEX 2: O(1) Extractor Index
  // ========================================
  "extractors": {
    // Key: "provider:instrumentor"
    "openai:traceloop": {
      "steps": [
        {
          "operation": "direct_copy",
          "source": "gen_ai.request.model",
          "target": "model"
        },
        {
          "operation": "reconstruct_array_from_flattened",
          "source_prefix": "gen_ai.completion.0.message.tool_calls",
          "target": "tool_calls",
          "preserve_json_strings": true,
          "json_string_fields": ["function.arguments"]
        }
      ]
    }
  },
  
  // ========================================
  // INDEX 3: O(1) Mapping Index
  // ========================================
  "mappings": {
    // Key: provider
    "openai": {
      "outputs": {
        "tool_calls": {
          "source": "tool_calls",
          "required": false
        }
      }
    }
  },
  
  // ========================================
  // INDEX 4: Transform Registry
  // ========================================
  "transforms": {
    "reconstruct_array_from_flattened": {
      "description": "Reconstruct array from flattened attributes",
      "algorithm": "regex_index_extraction"
    }
  }
}
```

### **O(1) Performance**

```python
# Detection: O(1)
signature = "|".join(sorted(span.attributes.keys()))
match = bundle["signature_index"][signature]  # Hash lookup!

# Extraction: O(1) lookup + O(m) steps
extractor = bundle["extractors"][f"{provider}:{instrumentor}"]  # Hash lookup!

# Mapping: O(1) lookup + O(f) fields
mappings = bundle["mappings"][provider]  # Hash lookup!
```

**Complexity**: O(1) + O(m) + O(f) where m and f are small constants (~10-30)

---

## ğŸŒ Phase 5: Cross-Language Runtime

### **Purpose**

Load and interpret the bundle in **any language** with **no code changes**.

### **The Key Principle**

- **Bundle** = Data (JSON with O(1) indexes)
- **Interpreter** = Code (stable, written once)
- DSL changes â†’ Bundle changes (no code changes!)

### **Implementation Per Language**

#### **Python Interpreter**

**File**: `src/honeyhive/tracer/processing/semantic_conventions/dsl_interpreter.py`

```python
class DSLInterpreter:
    def __init__(self, bundle_path: Path):
        with open(bundle_path) as f:
            self.bundle = json.load(f)
    
    def detect_provider(self, attributes: Dict) -> Optional[str]:
        """O(1) detection using signature index."""
        signature = "|".join(sorted(attributes.keys()))
        match = self.bundle["signature_index"].get(signature)
        return match["provider"] if match else None
    
    def extract_data(self, provider: str, instrumentor: str, attributes: Dict) -> Dict:
        """O(1) extraction using extractor index."""
        extractor_key = f"{provider}:{instrumentor}"
        extractor = self.bundle["extractors"][extractor_key]
        
        extracted = {}
        for step in extractor["steps"]:
            result = self._execute_step(step, attributes, extracted)
            if result is not None:
                extracted[step["target"]] = result
        
        return extracted
```

#### **TypeScript Interpreter**

**File**: `sdk/typescript/src/tracer/dsl-interpreter.ts`

```typescript
export class DSLInterpreter {
  private bundle: DSLBundle;
  
  constructor(bundlePath: string) {
    this.bundle = JSON.parse(fs.readFileSync(bundlePath, 'utf-8'));
  }
  
  detectProvider(attributes: Record<string, any>): string | null {
    const signature = Object.keys(attributes).sort().join('|');
    const match = this.bundle.signature_index[signature];
    return match ? match.provider : null;
  }
  
  extractData(provider: string, instrumentor: string, attributes: Record<string, any>): Record<string, any> {
    const extractorKey = `${provider}:${instrumentor}`;
    const extractor = this.bundle.extractors[extractorKey];
    
    const extracted: Record<string, any> = {};
    for (const step of extractor.steps) {
      const result = this.executeStep(step, attributes, extracted);
      if (result !== null) extracted[step.target] = result;
    }
    
    return extracted;
  }
}
```

#### **Go Interpreter**

**File**: `sdk/go/tracer/dsl_interpreter.go`

```go
type DSLInterpreter struct {
    bundle DSLBundle
}

func NewDSLInterpreter(bundlePath string) (*DSLInterpreter, error) {
    data, _ := ioutil.ReadFile(bundlePath)
    var bundle DSLBundle
    json.Unmarshal(data, &bundle)
    return &DSLInterpreter{bundle: bundle}, nil
}

func (d *DSLInterpreter) DetectProvider(attributes map[string]interface{}) string {
    keys := make([]string, 0, len(attributes))
    for k := range attributes {
        keys = append(keys, k)
    }
    sort.Strings(keys)
    signature := strings.Join(keys, "|")
    
    if match, ok := d.bundle.SignatureIndex[signature]; ok {
        return match.Provider
    }
    return ""
}
```

### **Key Point**

**All three languages**:
- Load the **same JSON bundle**
- Use the **same O(1) indexes**
- Execute the **same DSL operations**
- **No code changes** when bundle updates

---

## ğŸ› ï¸ Tools & Utilities

### **1. Provider Schema Extraction**

```bash
# Extract OpenAI schema
python scripts/extract_provider_schema.py openai

# Output:
# provider_response_schemas/openai/v2025-01-30.json
# provider_response_schemas/openai/CRITICAL_FINDINGS.md
```

### **2. Semantic Convention Discovery**

```bash
# Discover Traceloop attributes
python scripts/analyze_instrumentor_source.py traceloop

# Output:
# config/semantic_conventions/traceloop/source_analysis.yaml
# config/semantic_conventions/traceloop/openai.yaml.template
```

### **3. DSL Bundle Compilation**

```bash
# Compile all YAML configs to O(1) bundle
python scripts/compile_dsl_bundle.py

# Output:
# config/dsl/compiled/dsl-bundle.json (with O(1) indexes)
```

### **4. Bundle Format Converter (NEW)**

**Purpose**: Convert bundle to language-specific optimized formats

**Script**: `scripts/convert_bundle_format.py`

```bash
# Convert to Python pickle (for performance)
python scripts/convert_bundle_format.py --input dsl-bundle.json \
                                        --output dsl-bundle.pkl \
                                        --format pickle

# Convert to MessagePack (compact binary)
python scripts/convert_bundle_format.py --input dsl-bundle.json \
                                        --output dsl-bundle.msgpack \
                                        --format msgpack

# Convert to CBOR (Go-friendly binary)
python scripts/convert_bundle_format.py --input dsl-bundle.json \
                                        --output dsl-bundle.cbor \
                                        --format cbor
```

**Supported Formats**:
- **JSON** (universal, human-readable, ~2MB)
- **Pickle** (Python, fastest, ~1MB)
- **MessagePack** (compact binary, ~1.5MB, all languages)
- **CBOR** (efficient binary, ~1.5MB, Go-friendly)

### **5. Coverage Validator (Future)**

```bash
# Validate DSL coverage against provider schema
python scripts/validate_dsl_coverage.py openai

# Output:
# Coverage: 85%
# Missing: tool_calls, refusal, audio
```

### **6. DSL Test Suite (Future)**

```bash
# Test DSL extraction against schema examples
python scripts/test_dsl_against_examples.py openai

# Output:
# 11/11 examples passed
# tool_calls.json: âœ… All fields extracted
# refusal.json: âœ… All fields extracted
```

---

## ğŸš€ Release Process

### **When DSL Changes**

```bash
# ========================================
# Step 1: Update YAML Sources
# ========================================
vim config/dsl/providers/openai/navigation_rules.yaml
# (Add tool_calls extraction)

# ========================================
# Step 2: Compile to Bundle
# ========================================
python scripts/compile_dsl_bundle.py

# Output: config/dsl/compiled/dsl-bundle.json

# ========================================
# Step 3: Convert to Language-Specific Formats
# ========================================
# Python (pickle for performance)
python scripts/convert_bundle_format.py \
    --input dsl-bundle.json \
    --output dsl-bundle.pkl \
    --format pickle

# TypeScript (keep JSON)
cp dsl-bundle.json sdk/typescript/src/tracer/

# Go (MessagePack for efficiency)
python scripts/convert_bundle_format.py \
    --input dsl-bundle.json \
    --output dsl-bundle.msgpack \
    --format msgpack
cp dsl-bundle.msgpack sdk/go/tracer/

# ========================================
# Step 4: Release SDKs (NO CODE CHANGES!)
# ========================================
# Python
cd sdk/python
poetry version patch
poetry build
poetry publish

# TypeScript
cd sdk/typescript
npm version patch
npm publish

# Go
cd sdk/go
git tag v1.2.3
git push --tags
```

### **Version Compatibility**

Bundle includes version number:
```json
{
  "version": "4.0",
  "min_interpreter_version": "1.0",
  "max_interpreter_version": "2.0"
}
```

Interpreters check compatibility:
```python
def load_bundle(bundle_path):
    bundle = json.load(open(bundle_path))
    
    if not is_compatible(bundle["version"], INTERPRETER_VERSION):
        raise ValueError(f"Bundle v{bundle['version']} not compatible with interpreter v{INTERPRETER_VERSION}")
    
    return bundle
```

---

## ğŸ“Š Complete Flow Example

### **Scenario: Add OpenAI Tool Calls Support**

#### **1. Provider Schema** (Already Extracted)
```json
// provider_response_schemas/openai/v2025-01-30.json
{
  "tool_calls": {
    "type": "array",
    "items": {
      "properties": {
        "function": {
          "properties": {
            "arguments": {
              "type": "string",        // â† JSON string!
              "format": "json-string"  // â† Critical!
            }
          }
        }
      }
    }
  }
}
```

#### **2. Semantic Convention** (Already Discovered)
```yaml
# config/semantic_conventions/traceloop/source_analysis.yaml
discovered_attributes:
  - "gen_ai.completion.0.message.tool_calls.0.id"
  - "gen_ai.completion.0.message.tool_calls.0.function.name"
  - "gen_ai.completion.0.message.tool_calls.0.function.arguments"
```

#### **3. YAML DSL** (Human Creates Using Above)
```yaml
# config/dsl/providers/openai/navigation_rules.yaml
traceloop_tool_calls_flattened:
  source_field: "gen_ai.completion.0.message.tool_calls"
  extraction_method: "array_reconstruction"
  preserve_json_strings: true           # â† From schema!
  json_string_fields:
    - "function.arguments"              # â† From schema!
```

#### **4. Bundle Compilation** (Automatic)
```bash
python scripts/compile_dsl_bundle.py
```

```json
// dsl-bundle.json (auto-generated)
{
  "extractors": {
    "openai:traceloop": {
      "steps": [
        {
          "operation": "reconstruct_array_from_flattened",
          "source_prefix": "gen_ai.completion.0.message.tool_calls",
          "target": "tool_calls",
          "preserve_json_strings": true,
          "json_string_fields": ["function.arguments"]
        }
      ]
    }
  }
}
```

#### **5. Runtime** (Zero Code Changes)
```python
# Python interpreter (unchanged)
interpreter = DSLInterpreter("dsl-bundle.json")  # New bundle, same code!

extracted = interpreter.extract_data("openai", "traceloop", span.attributes)
# â†’ extracted["tool_calls"] = [{"function": {"arguments": '{"location": "SF"}'}}]
# â†’ JSON string preserved! âœ…
```

---

## ğŸ“‹ Summary

### **The Complete System**

1. **Provider Schemas** â†’ Understand API responses
2. **Semantic Conventions** â†’ Discover instrumentor attributes
3. **YAML DSL** â†’ Single source of truth (informed by 1 & 2)
4. **Bundle Compilation** â†’ O(1) optimized indexes
5. **Cross-Language Runtime** â†’ Load bundle, no code changes

### **Key Benefits**

âœ… **Config-Driven**: DSL changes â†’ bundle changes (no code!)  
âœ… **O(1) Performance**: Pre-computed indexes  
âœ… **Cross-Language**: Same bundle for Python/TypeScript/Go  
âœ… **Data Fidelity**: Provider schemas ensure accuracy  
âœ… **Maintainable**: Programmatic discovery + human curation  
âœ… **Scalable**: Works with 10 or 100 providers  

### **File Locations**

```
python-sdk/
â”œâ”€â”€ .agent-os/standards/architecture/
â”‚   â””â”€â”€ MASTER_DSL_ARCHITECTURE.md        # â† THIS FILE
â”‚
â”œâ”€â”€ provider_response_schemas/            # Phase 1
â”‚   â””â”€â”€ {provider}/
â”‚       â”œâ”€â”€ v{version}.json
â”‚       â””â”€â”€ CRITICAL_FINDINGS.md
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ dsl/providers/{provider}/         # Phase 3a
â”‚   â”‚   â”œâ”€â”€ structure_patterns.yaml
â”‚   â”‚   â”œâ”€â”€ navigation_rules.yaml
â”‚   â”‚   â”œâ”€â”€ transforms.yaml
â”‚   â”‚   â””â”€â”€ field_mappings.yaml
â”‚   â”‚
â”‚   â”œâ”€â”€ semantic_conventions/{instrumentor}/  # Phase 3b
â”‚   â”‚   â””â”€â”€ {provider}.yaml
â”‚   â”‚
â”‚   â””â”€â”€ dsl/compiled/                     # Phase 4
â”‚       â””â”€â”€ dsl-bundle.json
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ extract_provider_schema.py        # Phase 1
â”‚   â”œâ”€â”€ analyze_instrumentor_source.py    # Phase 2
â”‚   â”œâ”€â”€ compile_dsl_bundle.py             # Phase 4
â”‚   â””â”€â”€ convert_bundle_format.py          # Utility
â”‚
â””â”€â”€ src/honeyhive/tracer/processing/semantic_conventions/
    â”œâ”€â”€ dsl_interpreter.py                # Phase 5 (Python)
    â””â”€â”€ dsl-bundle.{json|pkl}             # Runtime bundle
```

---

**Last Updated**: 2025-09-30  
**Status**: Unified architecture complete  
**Next Steps**: Implement missing tools (bundle compiler, format converter)

