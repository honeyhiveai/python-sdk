# DSL Framework Analysis & Schema Integration

**Date**: 2025-09-30  
**Purpose**: Analyze current DSL framework scope and identify gaps for schema integration

---

## üîç Current State Analysis

### **What Exists**

#### **1. Provider Schema Extraction Framework** ‚úÖ (NEW - Just Completed)
**Location**: `.agent-os/standards/ai-assistant/provider-schema-extraction/`

**Purpose**: Extract provider API response schemas

**Output**:
```
provider_response_schemas/{provider}/
‚îú‚îÄ‚îÄ v{version}.json          # JSON Schema of API responses
‚îú‚îÄ‚îÄ examples/                # Validated example responses
‚îú‚îÄ‚îÄ CHANGELOG.md            # Version history
‚îú‚îÄ‚îÄ CRITICAL_FINDINGS.md    # DSL integration guidance
‚îî‚îÄ‚îÄ SDK_SOURCES.md          # Source tracking
```

**Status**: ‚úÖ Complete for OpenAI (Phases 0-6)

---

#### **2. Provider DSL Development Framework** ‚úÖ (Existing)
**Location**: `.agent-os/standards/ai-assistant/provider-dsl-development/`

**Purpose**: Build DSL configuration files

**Phases**:
- **Phase 0**: Setup (RESEARCH_SOURCES.md)
- **Phase 1**: Official docs discovery (API, models, pricing, changelog)
- **Phase 2**: Instrumentor support verification (Traceloop, OpenInference, OpenLit)
- **Phase 3**: Model & pricing data collection
- **Phase 4**: Structure patterns development (detection patterns)
- **Phase 5**: Navigation rules development
- **Phase 6**: Field mappings development
- **Phase 7**: Transforms development
- **Phase 7.5**: Pre-compilation validation
- **Phase 8**: Compilation & validation
- **Phase 9**: Documentation finalization

**Output**:
```
config/dsl/providers/{provider}/
‚îú‚îÄ‚îÄ RESEARCH_SOURCES.md           # Evidence & sources
‚îú‚îÄ‚îÄ structure_patterns.yaml        # Detection patterns
‚îú‚îÄ‚îÄ navigation_rules.yaml          # Field extraction rules
‚îú‚îÄ‚îÄ transforms.yaml                # Transform configs
‚îî‚îÄ‚îÄ field_mappings.yaml            # HoneyHive schema mappings
```

**Status**: ‚úÖ Framework complete, OpenAI at 30% coverage

---

#### **3. Semantic Convention Definitions** ‚ö†Ô∏è (Manually Created)
**Location**: `src/honeyhive/tracer/semantic_conventions/definitions/`

**Purpose**: Define how to detect and map semantic conventions from instrumentors

**Files** (Manually Created):
```python
honeyhive_v1_0_0.py      # HoneyHive native convention
openinference_v0_1_31.py # OpenInference (Arize)
openlit_v1_0_0.py        # OpenLit
traceloop_v0_46_2.py     # Traceloop
```

**Structure** (Python dictionaries):
```python
CONVENTION_DEFINITION = {
    "provider": "traceloop",
    "version": "0.46.2",
    "detection_patterns": {
        "required_prefixes": ["gen_ai.", "llm."],
        "signature_attributes": [...],
        "unique_attributes": [...]
    },
    "input_mapping": {
        "mappings": {
            "gen_ai.prompt.*": {
                "target": "chat_history",
                "transform": "parse_flattened_messages"
            }
        }
    },
    "output_mapping": {...},
    "config_mapping": {...},
    "metadata_mapping": {...}
}
```

**Status**: ‚ö†Ô∏è **MANUALLY CREATED - NOT COVERED BY ANY FRAMEWORK**

---

## ‚ùì The Gap

### **What's Missing**

The **semantic convention definitions** are **manually created** and **not generated by any framework**.

### **Why This Is a Problem**

1. **Duplication**: The DSL framework creates YAML configs that overlap with semantic convention definitions
2. **Inconsistency**: Two sources of truth (Python defs vs YAML configs)
3. **Manual Work**: Semantic convention defs are hand-written, error-prone
4. **No Schema Integration**: Semantic convention defs don't use the schema framework output
5. **Maintenance Burden**: When APIs change, must update both Python defs AND YAML configs

---

## üéØ What Each Framework Covers

### **Schema Extraction Framework**

**Covers**:
- ‚úÖ Provider API response structure (what fields exist)
- ‚úÖ Field types (string, array, object, null)
- ‚úÖ Format hints (json-string, base64)
- ‚úÖ Validated examples
- ‚úÖ Critical findings for DSL

**Does NOT Cover**:
- ‚ùå Instrumentor attribute patterns
- ‚ùå How to detect which instrumentor is being used
- ‚ùå How to map instrumentor attributes to HoneyHive schema

---

### **DSL Development Framework**

**Covers**:
- ‚úÖ Provider metadata (models, pricing)
- ‚úÖ Instrumentor detection patterns (Phase 4: structure_patterns.yaml)
- ‚úÖ Field extraction rules (Phase 5: navigation_rules.yaml)
- ‚úÖ Transform configurations (Phase 7: transforms.yaml)
- ‚úÖ HoneyHive schema mappings (Phase 6: field_mappings.yaml)

**Does NOT Cover**:
- ‚ùå Provider API response schemas (now covered by schema framework!)
- ‚ùå Semantic convention definition Python files
- ‚ùå Using schema framework output to inform DSL development

---

### **Semantic Convention Definitions (Manual)**

**Covers**:
- ‚úÖ Instrumentor detection patterns
- ‚úÖ Input/output/config/metadata mappings
- ‚úÖ Transform specifications

**Does NOT Cover**:
- ‚ùå Provider API response schemas
- ‚ùå Automated generation from schemas
- ‚ùå YAML-based configuration

**Status**: üö® **ORPHANED - NO FRAMEWORK GENERATES THESE**

---

## üîÑ Overlap Analysis

### **Duplication Between Systems**

| Concern | Semantic Conv Defs (Python) | DSL Configs (YAML) | Schema Framework (JSON) |
|---------|------------------------------|---------------------|-------------------------|
| **Detection patterns** | ‚úÖ Yes (in Python dict) | ‚úÖ Yes (structure_patterns.yaml) | ‚ùå No |
| **Field mappings** | ‚úÖ Yes (input/output/config/metadata) | ‚úÖ Yes (field_mappings.yaml) | ‚ùå No |
| **Transforms** | ‚úÖ Yes (transform names in mappings) | ‚úÖ Yes (transforms.yaml) | ‚ùå No |
| **Provider API schema** | ‚ùå No | ‚ùå No | ‚úÖ Yes |
| **Instrumentor attributes** | ‚úÖ Yes (gen_ai.*, llm.*) | ‚úÖ Yes (navigation_rules.yaml) | ‚ùå No |

**Issue**: Detection patterns and mappings exist in **TWO PLACES**:
1. Python semantic convention definitions
2. YAML DSL configs

---

## üöÄ Integration Opportunities

### **1. Schema Framework ‚Üí DSL Framework**

**Already Identified** (see `FRAMEWORK_INTEGRATION_MAP.md`):

Use schema framework output to inform DSL development:
- Schema tells us what fields exist ‚Üí DSL Phase 5 (navigation rules)
- Schema tells us field types ‚Üí DSL Phase 7 (transforms)
- Schema tells us critical handling ‚Üí DSL Phase 6 (field mappings)

**Status**: ‚úÖ Documented, ready to implement

---

### **2. DSL Framework ‚Üí Semantic Convention Definitions** (NEW GAP)

**Opportunity**: Generate semantic convention Python definitions from DSL YAML configs

**Why**: The DSL framework already creates:
- Detection patterns (structure_patterns.yaml)
- Field mappings (field_mappings.yaml, navigation_rules.yaml)
- Transform specs (transforms.yaml)

These are the **exact same things** in semantic convention definitions!

**Solution**: Add a phase to DSL framework to generate semantic convention definition files

---

### **3. Schema Framework ‚Üí Semantic Convention Definitions** (NEW GAP)

**Opportunity**: Use schema to validate semantic convention field paths

**Why**: Schema tells us what fields exist in provider responses. Semantic conventions should only reference fields that actually exist.

**Solution**: Validate semantic convention mappings against provider schema

---

## üí° Proposed Solution

### **Refactor: Unified Provider Configuration System**

#### **Architecture**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. SCHEMA EXTRACTION FRAMEWORK                              ‚îÇ
‚îÇ    Extract provider API response structure                  ‚îÇ
‚îÇ    Output: JSON Schema + Examples                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. DSL DEVELOPMENT FRAMEWORK (Enhanced)                     ‚îÇ
‚îÇ    Build YAML configs using schema                          ‚îÇ
‚îÇ    Output: structure_patterns.yaml, navigation_rules.yaml,  ‚îÇ
‚îÇ            transforms.yaml, field_mappings.yaml             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. SEMANTIC CONVENTION GENERATOR (NEW Phase 9.5)            ‚îÇ
‚îÇ    Generate Python definitions from YAML configs            ‚îÇ
‚îÇ    Output: {instrumentor}_v{version}.py                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. BUNDLE COMPILATION                                       ‚îÇ
‚îÇ    Compile all configs into runtime bundle                  ‚îÇ
‚îÇ    Output: compiled_providers.pkl                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### **New Phase: 9.5 - Semantic Convention Generation**

**Add to DSL Framework**:

**Location**: `.agent-os/standards/ai-assistant/provider-dsl-development/phases/9.5/`

**Purpose**: Generate Python semantic convention definitions from YAML configs

**Input**:
- `structure_patterns.yaml` (detection patterns)
- `field_mappings.yaml` (mappings)
- `navigation_rules.yaml` (field paths)
- `transforms.yaml` (transform specs)

**Output**:
```python
# src/honeyhive/tracer/semantic_conventions/definitions/{provider}_{instrumentor}_v{version}.py

CONVENTION_DEFINITION = {
    "provider": "openai",
    "instrumentor": "traceloop",
    "version": "0.46.2",
    "detection_patterns": {
        # Generated from structure_patterns.yaml
    },
    "input_mapping": {
        # Generated from field_mappings.yaml + navigation_rules.yaml
    },
    "output_mapping": {
        # Generated from field_mappings.yaml
    },
    "config_mapping": {
        # Generated from field_mappings.yaml
    },
    "metadata_mapping": {
        # Generated from field_mappings.yaml
    }
}
```

**Script**: `scripts/generate_semantic_convention_from_dsl.py`

```python
#!/usr/bin/env python3
"""Generate semantic convention definitions from DSL YAML configs."""

import yaml
import json
from pathlib import Path
from typing import Dict, Any

def generate_convention_definition(provider: str) -> Dict[str, Any]:
    """Generate convention definition from DSL configs."""
    
    # Load YAML configs
    base_path = Path(f"config/dsl/providers/{provider}")
    
    with open(base_path / "structure_patterns.yaml") as f:
        structure = yaml.safe_load(f)
    
    with open(base_path / "field_mappings.yaml") as f:
        mappings = yaml.safe_load(f)
    
    with open(base_path / "navigation_rules.yaml") as f:
        nav_rules = yaml.safe_load(f)
    
    # Generate definition for each instrumentor
    definitions = {}
    
    for pattern_name, pattern in structure["patterns"].items():
        instrumentor = pattern["instrumentor_framework"]
        
        definition = {
            "provider": provider,
            "instrumentor": instrumentor,
            "version": structure["version"],
            "detection_patterns": {
                "signature_attributes": pattern["signature_fields"],
                "optional_attributes": pattern.get("optional_fields", []),
                "confidence_weight": pattern["confidence_weight"]
            },
            "input_mapping": generate_input_mapping(mappings, nav_rules, instrumentor),
            "output_mapping": generate_output_mapping(mappings, nav_rules, instrumentor),
            "config_mapping": generate_config_mapping(mappings, nav_rules, instrumentor),
            "metadata_mapping": generate_metadata_mapping(mappings, nav_rules, instrumentor)
        }
        
        definitions[instrumentor] = definition
    
    return definitions

def generate_input_mapping(mappings, nav_rules, instrumentor):
    """Generate input mapping from field_mappings and navigation_rules."""
    # Implementation here
    pass

# ... other generation functions
```

---

### **Enhanced Phase 5: Navigation Rules (Use Schema)**

**Update DSL Framework Phase 5**:

**Current**: Manually create navigation rules from instrumentor research

**Enhanced**: Use schema framework output to inform navigation rules

**Process**:
1. Read schema: `provider_response_schemas/{provider}/v{version}.json`
2. For each schema field:
   - Check field type (array, string, object, null)
   - Check format hints (json-string, base64)
   - Read critical findings
3. Create navigation rules for each instrumentor:
   - Map schema field ‚Üí instrumentor attribute path
   - Specify extraction method based on type
   - Add special handling based on format

**Example**:
```yaml
# Enhanced navigation_rules.yaml (informed by schema)

# Schema field: tool_calls (type: array, items with function.arguments format: json-string)
traceloop_tool_calls_flattened:
  source_field: "gen_ai.completion.0.message.tool_calls"
  extraction_method: "array_reconstruction"  # ‚Üê From schema type: array
  preserve_json_strings: true                # ‚Üê From schema format: json-string
  json_string_fields: ["function.arguments"] # ‚Üê From schema definition
  description: "Tool calls array (schema v2025-01-30, field: choices[].message.tool_calls)"
  schema_reference: "v2025-01-30#/schemas/ToolCall"  # ‚Üê Link to schema
```

---

## üìã Implementation Plan

### **Phase 1: Document Current State** ‚úÖ (This Document)

- [x] Analyze what each framework covers
- [x] Identify overlaps and gaps
- [x] Document the semantic convention orphan problem

### **Phase 2: Enhance DSL Framework to Use Schema**

**Tasks**:
1. Update Phase 5 (Navigation Rules):
   - Add schema reading step
   - Use schema types to determine extraction methods
   - Use schema format hints for special handling
   - Add schema reference comments to YAML

2. Update Phase 7 (Transforms):
   - Read CRITICAL_FINDINGS.md for special cases
   - Auto-detect required transforms from schema types
   - Validate transform params match schema structure

3. Update Phase 6 (Field Mappings):
   - Cross-reference schema fields with HoneyHive event schema
   - Validate all schema fields are mapped
   - Report coverage percentage

### **Phase 3: Add Semantic Convention Generation**

**Tasks**:
1. Create Phase 9.5 in DSL Framework:
   - Design semantic convention generation logic
   - Create generation script
   - Add to framework phases

2. Build `scripts/generate_semantic_convention_from_dsl.py`:
   - Parse YAML configs
   - Generate Python definition dictionaries
   - Write to semantic_conventions/definitions/

3. Update existing semantic convention definitions:
   - Regenerate from YAML (if YAML exists)
   - Or create YAML from definitions (if only Python exists)

### **Phase 4: Validation & Testing**

**Tasks**:
1. Validate generated definitions match manual ones
2. Test detection patterns work correctly
3. Test field mappings extract correctly
4. Update tests to use generated definitions

---

## üéØ Recommendations

### **Immediate (This Week)**

1. ‚úÖ **Document the gap** (this document)
2. ‚è≥ **Continue OpenAI DSL** using schema framework output (manual for now)
3. ‚è≥ **Design Phase 9.5** (semantic convention generation)

### **Short-Term (Next 2 Weeks)**

1. **Enhance DSL Framework Phase 5**:
   - Add schema reading
   - Auto-detect extraction methods from types
   - Add format hint handling

2. **Build Generation Script**:
   - `scripts/generate_semantic_convention_from_dsl.py`
   - Test with OpenAI YAML ‚Üí Python conversion

3. **Validate OpenAI**:
   - Generate semantic convention from YAML
   - Compare with manual definition
   - Fix discrepancies

### **Long-Term (Next Month)**

1. **Deprecate Manual Definitions**:
   - Generate all semantic conventions from YAML
   - Remove manual Python files
   - Use generated definitions only

2. **Complete Framework Integration**:
   - Schema Framework ‚Üí DSL Framework ‚Üí Semantic Conventions
   - Full automation pipeline
   - Validation at each step

---

## üö® Critical Insights

### **1. The Real Problem**

The **semantic convention definitions are orphaned** - no framework generates them. They're manually created and duplicate work done in the DSL framework.

### **2. The Solution**

**Generate semantic convention definitions from DSL YAML configs** - they contain the same information!

### **3. The Opportunity**

With schema framework + enhanced DSL framework + semantic convention generation, we get:
- ‚úÖ **Single source of truth**: Schema defines what exists
- ‚úÖ **Automated generation**: DSL framework creates configs, then Python definitions
- ‚úÖ **Validation**: Schema validates DSL configs, DSL configs generate definitions
- ‚úÖ **Maintainability**: Update YAML once, regenerate Python automatically

---

## üìä Current vs Proposed Flow

### **Current (Manual, Duplicated)**

```
1. Research provider API (manual)
2. Create DSL YAML configs (DSL framework)
3. Create semantic convention Python defs (MANUAL! ‚ùå)
4. Compile bundle
```

### **Proposed (Automated, Unified)**

```
1. Extract schema (Schema Framework) ‚úÖ
2. Create DSL YAML configs (DSL Framework, informed by schema) ‚úÖ
3. Generate semantic convention defs (NEW Phase 9.5) ‚è≥
4. Validate & compile bundle
```

---

**Last Updated**: 2025-09-30  
**Status**: Gap identified, solution designed, ready to implement

