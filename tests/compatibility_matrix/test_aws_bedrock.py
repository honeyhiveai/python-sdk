#!/usr/bin/env python3
"""
AWS Bedrock Compatibility Test for HoneyHive SDK

Tests AWS Bedrock integration using OpenInference instrumentation with HoneyHive's
"Bring Your Own Instrumentor" pattern.
"""

import os
import sys
import json
from typing import Optional

def test_bedrock_integration():
    """Test AWS Bedrock integration with HoneyHive via OpenInference instrumentation."""
    
    # Check required environment variables
    api_key = os.getenv("HH_API_KEY")
    project = os.getenv("HH_PROJECT")
    aws_access_key = os.getenv("AWS_ACCESS_KEY_ID")
    aws_secret_key = os.getenv("AWS_SECRET_ACCESS_KEY")
    aws_region = os.getenv("AWS_DEFAULT_REGION", "us-east-1")
    
    if not all([api_key, project, aws_access_key, aws_secret_key]):
        print("‚ùå Missing required environment variables:")
        print("   - HH_API_KEY (HoneyHive API key)")
        print("   - HH_PROJECT (HoneyHive project)")
        print("   - AWS_ACCESS_KEY_ID (AWS access key)")
        print("   - AWS_SECRET_ACCESS_KEY (AWS secret key)")
        print("   - AWS_DEFAULT_REGION (optional, defaults to us-east-1)")
        return False
    
    try:
        # Import dependencies
        from honeyhive import HoneyHiveTracer
        from openinference.instrumentation.bedrock import BedrockInstrumentor
        import boto3
        
        print("üîß Setting up AWS Bedrock with HoneyHive integration...")
        
        # 1. Initialize OpenInference instrumentor
        bedrock_instrumentor = BedrockInstrumentor()
        print("‚úì Bedrock instrumentor initialized")
        
        # 2. Initialize HoneyHive tracer with instrumentor
        tracer = HoneyHiveTracer.init(
            api_key=api_key,
            project=project,
            instrumentors=[bedrock_instrumentor],  # Pass instrumentor to HoneyHive
            source="compatibility_test"
        )
        print("‚úì HoneyHive tracer initialized with Bedrock instrumentor")
        
        # 3. Initialize AWS Bedrock client
        session = boto3.Session(
            aws_access_key_id=aws_access_key,
            aws_secret_access_key=aws_secret_key,
            region_name=aws_region
        )
        client = session.client("bedrock-runtime")
        print(f"‚úì AWS Bedrock client initialized (region: {aws_region})")
        
        # 4. Test Claude model via Bedrock (automatically traced)
        print("üöÄ Testing AWS Bedrock with Claude model...")
        
        # Prepare request for Claude
        claude_request = {
            "prompt": "\n\nHuman: Say hello and confirm this is a compatibility test for HoneyHive + AWS Bedrock integration.\n\nAssistant:",
            "max_tokens_to_sample": 100,
            "temperature": 0.1,
            "top_p": 0.9
        }
        
        response = client.invoke_model(
            modelId="anthropic.claude-v2",
            body=json.dumps(claude_request),
            contentType="application/json",
            accept="application/json"
        )
        
        response_body = json.loads(response["body"].read())
        result_text = response_body.get("completion", "")
        print(f"‚úì Claude via Bedrock response: {result_text.strip()}")
        
        # 5. Test Amazon Titan model (if available)
        print("üîß Testing Amazon Titan model...")
        
        with tracer.enrich_span(
            metadata={"test_type": "compatibility", "provider": "aws_bedrock"},
            outputs={"model_used": "amazon.titan-text-express-v1"},
        ) as span:
            titan_request = {
                "inputText": "What is 2+2? Answer briefly.",
                "textGenerationConfig": {
                    "maxTokenCount": 50,
                    "temperature": 0.1,
                    "topP": 0.9
                }
            }
            
            try:
                titan_response = client.invoke_model(
                    modelId="amazon.titan-text-express-v1",
                    body=json.dumps(titan_request),
                    contentType="application/json",
                    accept="application/json"
                )
                
                titan_body = json.loads(titan_response["body"].read())
                titan_text = titan_body.get("results", [{}])[0].get("outputText", "")
                
                span_data = {
                    "model": "amazon.titan-text-express-v1",
                    "input_tokens": len(titan_request["inputText"].split()),
                    "output": titan_text.strip()
                }
                print(f"‚úì Titan response: {titan_text.strip()}")
                
            except Exception as e:
                print(f"‚ö†Ô∏è  Titan model not available or error: {e}")
                span_data = {"model": "amazon.titan-text-express-v1", "error": str(e)}
        
        # 6. Test Cohere model via Bedrock
        print("üîß Testing Cohere model via Bedrock...")
        
        with tracer.enrich_span(
            metadata={"test_type": "compatibility", "provider": "aws_bedrock_cohere"},
        ) as span:
            cohere_request = {
                "prompt": "Translate 'Hello World' to French:",
                "max_tokens": 30,
                "temperature": 0.1
            }
            
            try:
                cohere_response = client.invoke_model(
                    modelId="cohere.command-text-v14",
                    body=json.dumps(cohere_request),
                    contentType="application/json",
                    accept="application/json"
                )
                
                cohere_body = json.loads(cohere_response["body"].read())
                cohere_text = cohere_body.get("generations", [{}])[0].get("text", "")
                
                span_data = {
                    "model": "cohere.command-text-v14",
                    "response": cohere_text.strip()
                }
                print(f"‚úì Cohere via Bedrock response: {cohere_text.strip()}")
                
            except Exception as e:
                print(f"‚ö†Ô∏è  Cohere model not available or error: {e}")
                span_data = {"model": "cohere.command-text-v14", "error": str(e)}
        
        # 7. Force flush to ensure traces are sent
        print("üì§ Flushing traces...")
        tracer.force_flush(timeout=10.0)
        print("‚úì Traces flushed successfully")
        
        print("üéâ AWS Bedrock integration test completed successfully!")
        return True
        
    except ImportError as e:
        print(f"‚ùå Import error: {e}")
        print("üí° Install required packages:")
        print("   pip install honeyhive[opentelemetry]")
        print("   pip install openinference-instrumentation-bedrock")
        print("   pip install boto3")
        return False
        
    except Exception as e:
        print(f"‚ùå Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """Run the AWS Bedrock compatibility test."""
    print("üß™ HoneyHive + AWS Bedrock Compatibility Test")
    print("=" * 50)
    
    success = test_bedrock_integration()
    
    if success:
        print("\n‚úÖ AWS Bedrock compatibility: PASSED")
        sys.exit(0)
    else:
        print("\n‚ùå AWS Bedrock compatibility: FAILED")
        sys.exit(1)


if __name__ == "__main__":
    main()
